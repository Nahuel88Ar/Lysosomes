{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9fa4e-1e8a-47c0-bdfc-be41329f6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install skan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0882554-cef5-4f7b-bce3-ef696488e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import imageio\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "import czifile\n",
    "import tifffile as tiff\n",
    "\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_sauvola, threshold_local, threshold_otsu, gaussian\n",
    "from skimage.morphology import (\n",
    "    remove_small_objects, binary_opening, binary_closing, ball, binary_erosion,\n",
    "    skeletonize_3d, binary_dilation,disk\n",
    ")\n",
    "from skimage.measure import label\n",
    "from skimage.measure import label as _label\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.draw import line_nd\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt as _edt\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import napari\n",
    "import colorsys\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, simpledialog\n",
    "\n",
    "# ===============================\n",
    "# USER MODE\n",
    "# ===============================\n",
    "NEURITE_MODE = True\n",
    "EXPORT_FULLSIZE_OVERLAY = True\n",
    "\n",
    "# === NEW: Workflow B2 (manual edit via saved mask + rerun) ===\n",
    "USE_EDITED_MASK_IF_EXISTS = True\n",
    "EDITED_MASK_PATH = \"neuron_mask_edited.tif\"  # save this from Napari into output_dir\n",
    "\n",
    "# === NEW: edit lysosome table (points properties) in Napari and export edited CSV ===\n",
    "EDIT_LYSOSOME_TABLE_IN_NAPARI = True\n",
    "LYSOSOME_EDITED_CSV = \"lysosomes_with_cell_vs_outside_EDITED.csv\"\n",
    "\n",
    "# Hotkeys inside Napari:\n",
    "#   A = assign selected lysosomes to ID under mouse (from ID (viz) labels) and mark as \"cell\"\n",
    "#   X = mark selected lysosomes as \"outside\" and set cell_id = 0\n",
    "#   S = save edited CSV immediately (also auto-saves when you close Napari)\n",
    "\n",
    "# --- NEW: attach original blob fields from lysosome_blobs_regions_ALL.csv ---\n",
    "LYSOSOME_ALL_CSV = \"lysosome_blobs_regions_ALL.csv\"\n",
    "\n",
    "def attach_all_blob_fields(df_out: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensures df_out contains diameter_um + peak_gray taken from lysosome_blobs_regions_ALL.csv (by 'id').\n",
    "    Requires df_out to have column 'id' (your pipeline does).\n",
    "    \"\"\"\n",
    "    if not isinstance(df_out, pd.DataFrame) or df_out.empty:\n",
    "        return df_out\n",
    "\n",
    "    if \"id\" not in df_out.columns:\n",
    "        print(\"[export] WARNING: df_out has no 'id' column; cannot attach diameter_um/peak_gray from ALL.\")\n",
    "        return df_out\n",
    "\n",
    "    if not os.path.isfile(LYSOSOME_ALL_CSV):\n",
    "        print(f\"[export] WARNING: Missing {LYSOSOME_ALL_CSV}; cannot attach diameter_um/peak_gray from ALL.\")\n",
    "        return df_out\n",
    "\n",
    "    df_all = pd.read_csv(LYSOSOME_ALL_CSV)\n",
    "\n",
    "    need = {\"id\", \"diameter_um\", \"peak_gray\"}\n",
    "    if not need.issubset(df_all.columns):\n",
    "        print(f\"[export] WARNING: {LYSOSOME_ALL_CSV} missing columns {need - set(df_all.columns)}\")\n",
    "        return df_out\n",
    "\n",
    "    lookup = (\n",
    "        df_all[[\"id\", \"diameter_um\", \"peak_gray\"]]\n",
    "        .drop_duplicates(subset=[\"id\"])\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # Remove existing columns to avoid merge suffixes and force ALL-table values\n",
    "    for c in (\"diameter_um\", \"peak_gray\"):\n",
    "        if c in df_out.columns:\n",
    "            df_out = df_out.drop(columns=[c])\n",
    "\n",
    "    df_out = df_out.merge(lookup, on=\"id\", how=\"left\")\n",
    "    return df_out\n",
    "\n",
    "# OpenCV colors are BGR (not RGB)\n",
    "LYS_EDGE_BGR = (0, 0, 0)          # black outline\n",
    "LYS_MAGENTA_BGR = (255, 0, 255)   # magenta\n",
    "\n",
    "# ===============================\n",
    "# GUI (single unified interface)\n",
    "# Now ALSO includes:\n",
    "#   - DIAMETER_MIN_UM\n",
    "#   - DIAMETER_MAX_UM (optional; blank = no max)\n",
    "# ===============================\n",
    "def get_user_config_gui(\n",
    "    default_vxy_um=0.04,\n",
    "    default_vz_um=None,\n",
    "    default_erode_mult=1.0,\n",
    "    default_blob_threshold=0.001,\n",
    "\n",
    "    # >>> NEW defaults for interval filtering\n",
    "    default_diam_min_um=0.0,\n",
    "    default_diam_max_um=\"\",   # blank = no max\n",
    "\n",
    "    # advanced defaults (ONLY the 3 shown in GUI)\n",
    "    default_margin_um=0.5,\n",
    "    default_overlap_alpha=0.4,\n",
    "    default_neighbor_max_vox=6,     # hidden; fixed default\n",
    "    default_viz_min_voxels=200,\n",
    "\n",
    "    # >>> NEW advanced defaults (shown in GUI)\n",
    "    default_max_gap_um=2.0,         # µm (stitching max gap)\n",
    "    default_closing_radius_vox=7,   # voxels (ball radius for binary_closing)\n",
    "\n",
    "    # fixed defaults (not shown)\n",
    "    default_max_reasonable_vxy_um=0.5,\n",
    "    default_ch1_smooth_sigma=1.0,\n",
    "    default_blob_min_sigma=0.8,\n",
    "    default_blob_max_sigma=3.0,\n",
    "    default_blob_num_sigma=10,\n",
    "    default_radial_max_radius_nm=300.0,\n",
    "    default_radial_dr_nm=10.0,\n",
    "    default_radial_min_drop_fraction=0.5,\n",
    "\n",
    "    # neurite-friendly threshold defaults (fixed, not shown)\n",
    "    default_ch2_smooth_sigma=1.2,\n",
    "    default_thresh_block_size=201,\n",
    "    default_thresh_offset_std_mult=0.12,\n",
    "\n",
    "    default_video_fps=8,\n",
    "    default_launch_viewer=True,\n",
    "    default_generate_videos=True,\n",
    "):\n",
    "    cfg = {\"ok\": False}\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Lysosome + Neurite Segmentation (GUI)\")\n",
    "    root.resizable(False, False)\n",
    "\n",
    "    file_var = tk.StringVar(value=\"\")\n",
    "    out_var = tk.StringVar(value=\"\")\n",
    "\n",
    "    erode_var = tk.StringVar(value=str(default_erode_mult))\n",
    "    blob_var  = tk.StringVar(value=str(default_blob_threshold))\n",
    "\n",
    "    # >>> NEW: diameter interval entries (µm)\n",
    "    diam_min_var = tk.StringVar(value=str(default_diam_min_um))\n",
    "    diam_max_var = tk.StringVar(value=str(default_diam_max_um))\n",
    "\n",
    "    show_adv = tk.BooleanVar(value=False)\n",
    "\n",
    "    margin_var   = tk.StringVar(value=str(default_margin_um))\n",
    "    overlap_var  = tk.StringVar(value=str(default_overlap_alpha))\n",
    "    vizmin_var   = tk.StringVar(value=str(default_viz_min_voxels))\n",
    "\n",
    "    # >>> NEW: advanced entries\n",
    "    maxgap_var   = tk.StringVar(value=str(default_max_gap_um))\n",
    "    closing_var  = tk.StringVar(value=str(default_closing_radius_vox))\n",
    "\n",
    "    fps_var = tk.StringVar(value=str(default_video_fps))\n",
    "\n",
    "    launch_viewer_var = tk.BooleanVar(value=bool(default_launch_viewer))\n",
    "    gen_videos_var    = tk.BooleanVar(value=bool(default_generate_videos))\n",
    "\n",
    "    def _suggest_output_dir(fp):\n",
    "        if not fp:\n",
    "            return \"\"\n",
    "        raw_dir = os.path.dirname(fp)\n",
    "        raw_base = os.path.splitext(os.path.basename(fp))[0]\n",
    "        stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        return os.path.join(raw_dir, f\"{raw_base}_outputs_{stamp}\")\n",
    "\n",
    "    def browse_file():\n",
    "        fp = filedialog.askopenfilename(\n",
    "            title=\"Select image file\",\n",
    "            filetypes=[(\"Image files\", \"*.tif *.tiff *.czi\"), (\"All files\", \"*.*\")],\n",
    "        )\n",
    "        if fp:\n",
    "            file_var.set(fp)\n",
    "            if not out_var.get().strip():\n",
    "                out_var.set(_suggest_output_dir(fp))\n",
    "\n",
    "    def browse_output_dir():\n",
    "        d = filedialog.askdirectory(title=\"Select output folder\")\n",
    "        if d:\n",
    "            fp = file_var.get().strip()\n",
    "            if fp:\n",
    "                raw_base = os.path.splitext(os.path.basename(fp))[0]\n",
    "                stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                out_var.set(os.path.join(d, f\"{raw_base}_outputs_{stamp}\"))\n",
    "            else:\n",
    "                out_var.set(d)\n",
    "\n",
    "    def _err(msg):\n",
    "        messagebox.showerror(\"Invalid input\", msg)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    def _float_required(s, name):\n",
    "        s = (s or \"\").strip()\n",
    "        if s == \"\":\n",
    "            _err(f\"{name} is required.\")\n",
    "        try:\n",
    "            return float(s.replace(\",\", \".\"))\n",
    "        except Exception:\n",
    "            _err(f\"{name} must be a number (got: {s})\")\n",
    "\n",
    "    def _float_optional(s, name):\n",
    "        s = (s or \"\").strip()\n",
    "        if s == \"\":\n",
    "            return None\n",
    "        try:\n",
    "            return float(s.replace(\",\", \".\"))\n",
    "        except Exception:\n",
    "            _err(f\"{name} must be a number (got: {s})\")\n",
    "\n",
    "    def _int_required(s, name):\n",
    "        s = (s or \"\").strip()\n",
    "        if s == \"\":\n",
    "            _err(f\"{name} is required.\")\n",
    "        try:\n",
    "            return int(float(s.replace(\",\", \".\")))\n",
    "        except Exception:\n",
    "            _err(f\"{name} must be an integer (got: {s})\")\n",
    "\n",
    "    def _toggle_adv():\n",
    "        if show_adv.get():\n",
    "            adv_frame.grid()\n",
    "        else:\n",
    "            adv_frame.grid_remove()\n",
    "\n",
    "    def run_clicked():\n",
    "        fp = file_var.get().strip()\n",
    "        if not fp:\n",
    "            _err(\"Please select a file.\")\n",
    "        if not os.path.isfile(fp):\n",
    "            _err(\"Selected file does not exist.\")\n",
    "\n",
    "        outd = out_var.get().strip() or _suggest_output_dir(fp)\n",
    "\n",
    "        erode = _float_required(erode_var.get(), \"ERODE_MULT\")\n",
    "        blobt = _float_required(blob_var.get(), \"blob_log threshold\")\n",
    "        fps   = _int_required(fps_var.get(), \"video FPS\")\n",
    "\n",
    "        # >>> NEW: interval parsing\n",
    "        dmin = _float_required(diam_min_var.get(), \"DIAMETER_MIN_UM (µm)\")\n",
    "        dmax = _float_optional(diam_max_var.get(), \"DIAMETER_MAX_UM (µm)\")\n",
    "\n",
    "        if dmin < 0:\n",
    "            _err(\"DIAMETER_MIN_UM must be >= 0.\")\n",
    "        if dmax is not None:\n",
    "            if dmax <= dmin:\n",
    "                _err(\"DIAMETER_MAX_UM must be > DIAMETER_MIN_UM (or leave it blank).\")\n",
    "\n",
    "        margin  = _float_required(margin_var.get(), \"MARGIN_UM (µm)\")\n",
    "        overlap = _float_required(overlap_var.get(), \"OVERLAP_ALPHA (0..1)\")\n",
    "        vizmin  = _int_required(vizmin_var.get(), \"VIZ_MIN_VOXELS (voxels)\")\n",
    "\n",
    "        # >>> NEW: advanced parsing\n",
    "        max_gap_um = _float_required(maxgap_var.get(), \"MAX_GAP_UM (µm)\")\n",
    "        closing_r  = _int_required(closing_var.get(), \"CLOSING_RADIUS_VOX (voxels)\")\n",
    "\n",
    "        if max_gap_um <= 0:\n",
    "            _err(\"MAX_GAP_UM must be > 0.\")\n",
    "        if closing_r < 1:\n",
    "            _err(\"CLOSING_RADIUS_VOX must be >= 1.\")\n",
    "\n",
    "        if not (0.0 <= overlap <= 1.0):\n",
    "            _err(\"OVERLAP_ALPHA must be between 0 and 1.\")\n",
    "\n",
    "        cfg.update({\n",
    "            \"ok\": True,\n",
    "            \"file_path\": fp,\n",
    "            \"output_dir\": outd,\n",
    "\n",
    "            \"ERODE_MULT\": float(erode),\n",
    "            \"BLOB_THRESHOLD\": float(blobt),\n",
    "\n",
    "            \"DEFAULT_VX_VY_UM\": float(default_vxy_um),\n",
    "            \"DEFAULT_VZ_UM\": None if default_vz_um is None else float(default_vz_um),\n",
    "\n",
    "            \"MAX_REASONABLE_VXY_UM\": float(default_max_reasonable_vxy_um),\n",
    "\n",
    "            # >>> NEW: interval values\n",
    "            \"DIAMETER_MIN_UM\": float(dmin),\n",
    "            \"DIAMETER_MAX_UM\": None if (dmax is None) else float(dmax),\n",
    "\n",
    "            # Advanced only\n",
    "            \"MARGIN_UM\": float(margin),\n",
    "            \"OVERLAP_ALPHA\": float(overlap),\n",
    "            \"VIZ_MIN_VOXELS\": int(vizmin),\n",
    "\n",
    "            # >>> NEW advanced values\n",
    "            \"MAX_GAP_UM\": float(max_gap_um),\n",
    "            \"CLOSING_RADIUS_VOX\": int(closing_r),\n",
    "\n",
    "            # Fixed (hidden)\n",
    "            \"NEIGHBOR_MAX_VOX\": int(default_neighbor_max_vox),\n",
    "\n",
    "            # Fixed defaults (hidden)\n",
    "            \"CH1_SMOOTH_SIGMA\": float(default_ch1_smooth_sigma),\n",
    "            \"BLOB_MIN_SIGMA\": float(default_blob_min_sigma),\n",
    "            \"BLOB_MAX_SIGMA\": float(default_blob_max_sigma),\n",
    "            \"BLOB_NUM_SIGMA\": int(default_blob_num_sigma),\n",
    "\n",
    "            \"RADIAL_MAX_RADIUS_NM\": float(default_radial_max_radius_nm),\n",
    "            \"RADIAL_DR_NM\": float(default_radial_dr_nm),\n",
    "            \"RADIAL_MIN_DROP_FRACTION\": float(default_radial_min_drop_fraction),\n",
    "\n",
    "            \"CH2_SMOOTH_SIGMA\": float(default_ch2_smooth_sigma),\n",
    "            \"THRESH_BLOCK_SIZE\": int(default_thresh_block_size),\n",
    "            \"THRESH_OFFSET_STD_MULT\": float(default_thresh_offset_std_mult),\n",
    "\n",
    "            \"VIDEO_FPS\": int(fps),\n",
    "            \"LAUNCH_VIEWER\": bool(launch_viewer_var.get()),\n",
    "            \"GENERATE_VIDEOS\": bool(gen_videos_var.get()),\n",
    "        })\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "    def cancel_clicked():\n",
    "        root.destroy()\n",
    "\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", cancel_clicked)\n",
    "\n",
    "    pad = {\"padx\": 10, \"pady\": 6}\n",
    "    frm = ttk.Frame(root)\n",
    "    frm.grid(row=0, column=0, sticky=\"nsew\", **pad)\n",
    "\n",
    "    r = 0\n",
    "    ttk.Label(frm, text=\"Image file:\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=file_var, width=60).grid(row=r, column=1, sticky=\"we\")\n",
    "    ttk.Button(frm, text=\"Browse...\", command=browse_file).grid(row=r, column=2, sticky=\"e\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"Output folder:\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=out_var, width=60).grid(row=r, column=1, sticky=\"we\")\n",
    "    ttk.Button(frm, text=\"Browse...\", command=browse_output_dir).grid(row=r, column=2, sticky=\"e\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Separator(frm).grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=8)\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"ERODE_MULT:\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=erode_var, width=20).grid(row=r, column=1, sticky=\"w\")\n",
    "    ttk.Label(frm, text=\"unitless\").grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"blob_log threshold:\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=blob_var, width=20).grid(row=r, column=1, sticky=\"w\")\n",
    "    ttk.Label(frm, text=\"unitless\").grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    # >>> NEW: Diameter interval section\n",
    "    ttk.Separator(frm).grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=8)\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"Diameter interval (µm):\").grid(row=r, column=0, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"Min diameter (µm):\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=diam_min_var, width=20).grid(row=r, column=1, sticky=\"w\")\n",
    "    ttk.Label(frm, text=\"required\").grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"Max diameter (µm):\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=diam_max_var, width=20).grid(row=r, column=1, sticky=\"w\")\n",
    "    ttk.Label(frm, text=\"blank = no max\").grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Separator(frm).grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=8)\n",
    "    r += 1\n",
    "\n",
    "    ttk.Checkbutton(frm, text=\"Launch Napari viewer\", variable=launch_viewer_var)\\\n",
    "        .grid(row=r, column=0, columnspan=2, sticky=\"w\")\n",
    "    ttk.Checkbutton(frm, text=\"Generate videos\", variable=gen_videos_var)\\\n",
    "        .grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Label(frm, text=\"Video FPS:\").grid(row=r, column=0, sticky=\"w\")\n",
    "    ttk.Entry(frm, textvariable=fps_var, width=20).grid(row=r, column=1, sticky=\"w\")\n",
    "    ttk.Label(frm, text=\"frames/sec\").grid(row=r, column=2, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    ttk.Separator(frm).grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=8)\n",
    "    r += 1\n",
    "\n",
    "    ttk.Checkbutton(frm, text=\"Show advanced settings\", variable=show_adv, command=_toggle_adv)\\\n",
    "        .grid(row=r, column=0, columnspan=3, sticky=\"w\")\n",
    "    r += 1\n",
    "\n",
    "    adv_frame = ttk.LabelFrame(frm, text=\"Advanced\")\n",
    "    adv_frame.grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=6)\n",
    "    adv_frame.grid_remove()\n",
    "\n",
    "    rr = 0\n",
    "    def add_row(label_txt, var, hint):\n",
    "        nonlocal rr\n",
    "        ttk.Label(adv_frame, text=label_txt).grid(row=rr, column=0, sticky=\"w\", padx=8, pady=3)\n",
    "        ttk.Entry(adv_frame, textvariable=var, width=18).grid(row=rr, column=1, sticky=\"w\", padx=8, pady=3)\n",
    "        ttk.Label(adv_frame, text=hint).grid(row=rr, column=2, sticky=\"w\", padx=8, pady=3)\n",
    "        rr += 1\n",
    "\n",
    "    add_row(\"MARGIN_UM:\", margin_var, \"µm (soft band around mask)\")\n",
    "    add_row(\"OVERLAP_ALPHA:\", overlap_var, \"0..1 (sphere overlap fraction)\")\n",
    "    add_row(\"VIZ_MIN_VOXELS:\", vizmin_var, \"voxels (hide small components)\")\n",
    "\n",
    "    # >>> NEW advanced GUI rows\n",
    "    add_row(\"MAX_GAP_UM:\", maxgap_var, \"µm (stitch endpoints max gap)\")\n",
    "    add_row(\"CLOSING_RADIUS_VOX:\", closing_var, \"voxels (ball radius for binary_closing)\")\n",
    "\n",
    "    r += 1\n",
    "    ttk.Separator(frm).grid(row=r, column=0, columnspan=3, sticky=\"we\", pady=8)\n",
    "    r += 1\n",
    "\n",
    "    btns = ttk.Frame(frm)\n",
    "    btns.grid(row=r, column=0, columnspan=3, sticky=\"e\")\n",
    "    ttk.Button(btns, text=\"Cancel\", command=cancel_clicked).grid(row=0, column=0, padx=6)\n",
    "    ttk.Button(btns, text=\"Run\", command=run_clicked).grid(row=0, column=1, padx=6)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    if not cfg.get(\"ok\"):\n",
    "        raise SystemExit(\"Cancelled.\")\n",
    "    return cfg\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Metadata parsing\n",
    "# ===============================\n",
    "def _parse_ome_xml(xml_text):\n",
    "    if not xml_text:\n",
    "        return None, None, None\n",
    "\n",
    "    def grab(attr):\n",
    "        m = re.search(fr'PhysicalSize{attr}=\"([\\d\\.eE+-]+)\"', xml_text)\n",
    "        return float(m.group(1)) if m else None\n",
    "\n",
    "    return grab(\"X\"), grab(\"Y\"), grab(\"Z\")\n",
    "\n",
    "\n",
    "def _parse_czi_scaling(czi_text):\n",
    "    if not czi_text:\n",
    "        return None, None, None\n",
    "\n",
    "    if isinstance(czi_text, (bytes, bytearray)):\n",
    "        czi_text = czi_text.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    czi_text = czi_text.replace(\"\\x00\", \"\")\n",
    "\n",
    "    def _to_float(s):\n",
    "        if s is None:\n",
    "            return None\n",
    "        try:\n",
    "            return float(str(s).strip().replace(\",\", \".\"))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _to_um(val, unit_hint=None):\n",
    "        if val is None:\n",
    "            return None\n",
    "        if unit_hint:\n",
    "            u = str(unit_hint).strip().lower()\n",
    "            if u in (\"m\", \"meter\", \"metre\", \"meters\", \"metres\"):\n",
    "                return val * 1e6\n",
    "            if u in (\"µm\", \"um\", \"micron\", \"microns\", \"micrometer\", \"micrometre\"):\n",
    "                return val\n",
    "            if u in (\"nm\", \"nanometer\", \"nanometre\", \"nanometers\", \"nanometres\"):\n",
    "                return val / 1000.0\n",
    "\n",
    "        if val < 1e-3:\n",
    "            return val * 1e6\n",
    "        if val < 10:\n",
    "            return val\n",
    "        if val < 1e5:\n",
    "            return val / 1000.0\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        root = ET.fromstring(czi_text)\n",
    "    except Exception:\n",
    "        def _grab(axis):\n",
    "            mm = re.search(\n",
    "                rf'<Distance[^>]*Id=\"{axis}\"[^>]*>.*?<Value>\\s*([0-9eE\\+\\-\\.]+)\\s*</Value>',\n",
    "                czi_text,\n",
    "                flags=re.IGNORECASE | re.DOTALL,\n",
    "            )\n",
    "            return _to_float(mm.group(1)) if mm else None\n",
    "\n",
    "        return _to_um(_grab(\"X\")), _to_um(_grab(\"Y\")), _to_um(_grab(\"Z\"))\n",
    "\n",
    "    sx = sy = sz = None\n",
    "    for d in root.findall(\".//{*}Distance\"):\n",
    "        axis = d.attrib.get(\"Id\") or d.attrib.get(\"id\") or d.attrib.get(\"Axis\") or d.attrib.get(\"axis\")\n",
    "        if not axis:\n",
    "            continue\n",
    "        axis = axis.upper()\n",
    "        unit = d.attrib.get(\"Unit\") or d.attrib.get(\"unit\")\n",
    "\n",
    "        valf = _to_float(d.attrib.get(\"Value\") or d.attrib.get(\"value\"))\n",
    "\n",
    "        if valf is None:\n",
    "            v_el = d.find(\".//{*}Value\")\n",
    "            if v_el is not None and v_el.text:\n",
    "                valf = _to_float(v_el.text)\n",
    "\n",
    "        if valf is None:\n",
    "            for child in d.iter():\n",
    "                if child is d:\n",
    "                    continue\n",
    "                if str(child.tag).lower().endswith(\"value\"):\n",
    "                    valf = _to_float(child.attrib.get(\"Value\") or child.attrib.get(\"value\")) or _to_float(child.text)\n",
    "                    if valf is not None:\n",
    "                        break\n",
    "\n",
    "        val_um = _to_um(valf, unit_hint=unit)\n",
    "        if val_um is None:\n",
    "            continue\n",
    "\n",
    "        if axis == \"X\":\n",
    "            sx = val_um\n",
    "        elif axis == \"Y\":\n",
    "            sy = val_um\n",
    "        elif axis == \"Z\":\n",
    "            sz = val_um\n",
    "\n",
    "    return sx, sy, sz\n",
    "\n",
    "\n",
    "def load_any(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext in (\".tif\", \".tiff\"):\n",
    "        with tiff.TiffFile(file_path) as tf:\n",
    "            arr = tf.asarray()\n",
    "            try:\n",
    "                ome_xml = tf.ome_metadata\n",
    "            except Exception:\n",
    "                ome_xml = None\n",
    "            vx_um = vy_um = vz_um = None\n",
    "            if ome_xml:\n",
    "                vx_um, vy_um, vz_um = _parse_ome_xml(ome_xml)\n",
    "\n",
    "        img = np.squeeze(arr)\n",
    "        if img.ndim == 4:\n",
    "            if img.shape[0] == 2:\n",
    "                ch1, ch2 = img[0], img[1]\n",
    "            elif img.shape[1] == 2:\n",
    "                ch1, ch2 = img[:, 0], img[:, 1]\n",
    "            elif img.shape[-1] == 2:\n",
    "                ch1, ch2 = img[..., 0], img[..., 1]\n",
    "            else:\n",
    "                raise RuntimeError(\"Unexpected TIFF shape for 2 channels\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected TIFF shape\")\n",
    "        return ch1, ch2, (vx_um, vy_um, vz_um), {\"type\": \"tiff\"}\n",
    "\n",
    "    if ext == \".czi\":\n",
    "        with czifile.CziFile(file_path) as cf:\n",
    "            arr = cf.asarray()\n",
    "            try:\n",
    "                czi_xml = cf.metadata()\n",
    "            except Exception:\n",
    "                czi_xml = None\n",
    "\n",
    "        vx_um = vy_um = vz_um = None\n",
    "        if czi_xml:\n",
    "            vx_um, vy_um, vz_um = _parse_czi_scaling(czi_xml)\n",
    "\n",
    "        img = np.squeeze(arr)\n",
    "        if img.ndim == 4:\n",
    "            if img.shape[0] == 2:\n",
    "                ch1, ch2 = img[0], img[1]\n",
    "            elif img.shape[1] == 2:\n",
    "                ch1, ch2 = img[:, 0], img[:, 1]\n",
    "            elif img.shape[-1] == 2:\n",
    "                ch1, ch2 = img[..., 0], img[..., 1]\n",
    "            else:\n",
    "                raise RuntimeError(\"Unexpected CZI shape for 2 channels\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected CZI shape\")\n",
    "\n",
    "        return ch1, ch2, (vx_um, vy_um, vz_um), {\"type\": \"czi\"}\n",
    "\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# NEW (Option B): direction-aware stitching of broken neurites\n",
    "# ===============================\n",
    "def stitch_neurite_fragments_by_orientation(\n",
    "    neuron_mask,\n",
    "    vx_um, vy_um, vz_um,\n",
    "    max_gap_um=2,\n",
    "    cos_min=0.6,\n",
    "    bridge_dilate_radius_vox=1,\n",
    "):\n",
    "    if neuron_mask is None or neuron_mask.sum() == 0:\n",
    "        return neuron_mask\n",
    "\n",
    "    skel = skeletonize_3d(neuron_mask).astype(bool)\n",
    "    if skel.sum() == 0:\n",
    "        return neuron_mask\n",
    "\n",
    "    kernel = np.ones((3, 3, 3), dtype=np.uint8)\n",
    "    kernel[1, 1, 1] = 0\n",
    "    neigh = convolve(skel.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
    "\n",
    "    endpoints = skel & (neigh == 1)\n",
    "    pts = np.argwhere(endpoints)  # zyx\n",
    "    n = pts.shape[0]\n",
    "    if n < 2:\n",
    "        return neuron_mask\n",
    "\n",
    "    spacing = np.array([vz_um, vy_um, vx_um], dtype=np.float32)\n",
    "\n",
    "    dirs = np.zeros((n, 3), dtype=np.float32)\n",
    "    Z, Y, X = skel.shape\n",
    "\n",
    "    for i, (z, y, x) in enumerate(pts):\n",
    "        z1, z2 = max(0, z - 1), min(Z, z + 2)\n",
    "        y1, y2 = max(0, y - 1), min(Y, y + 2)\n",
    "        x1, x2 = max(0, x - 1), min(X, x + 2)\n",
    "\n",
    "        patch = skel[z1:z2, y1:y2, x1:x2]\n",
    "        nbrs = np.argwhere(patch)\n",
    "        nbrs = nbrs + np.array([z1, y1, x1], dtype=np.int32)\n",
    "\n",
    "        nbrs = nbrs[~((nbrs[:, 0] == z) & (nbrs[:, 1] == y) & (nbrs[:, 2] == x))]\n",
    "        if nbrs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        d2 = np.sum((nbrs - np.array([z, y, x], dtype=np.int32)) ** 2, axis=1)\n",
    "        nb = nbrs[int(np.argmin(d2))]\n",
    "\n",
    "        v_vox = (np.array([z, y, x], dtype=np.float32) - nb.astype(np.float32))\n",
    "        v_um = v_vox * spacing\n",
    "        norm = float(np.linalg.norm(v_um))\n",
    "        if norm > 0:\n",
    "            dirs[i] = v_um / norm\n",
    "\n",
    "    candidates = []\n",
    "    for i in range(n):\n",
    "        if not np.isfinite(dirs[i]).all() or np.linalg.norm(dirs[i]) == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, n):\n",
    "            if not np.isfinite(dirs[j]).all() or np.linalg.norm(dirs[j]) == 0:\n",
    "                continue\n",
    "\n",
    "            d_vox = (pts[j] - pts[i]).astype(np.float32)\n",
    "            d_um_vec = d_vox * spacing\n",
    "            dist = float(np.linalg.norm(d_um_vec))\n",
    "            if dist <= 0 or dist > max_gap_um:\n",
    "                continue\n",
    "\n",
    "            v = d_um_vec / dist\n",
    "            if float(np.dot(dirs[i], v)) < cos_min:\n",
    "                continue\n",
    "            if float(np.dot(dirs[j], -v)) < cos_min:\n",
    "                continue\n",
    "\n",
    "            candidates.append((dist, i, j))\n",
    "\n",
    "    if not candidates:\n",
    "        return neuron_mask\n",
    "\n",
    "    candidates.sort(key=lambda t: t[0])\n",
    "\n",
    "    used = np.zeros(n, dtype=bool)\n",
    "    bridge = np.zeros_like(neuron_mask, dtype=bool)\n",
    "\n",
    "    for dist, i, j in candidates:\n",
    "        if used[i] or used[j]:\n",
    "            continue\n",
    "        p1 = tuple(pts[i])\n",
    "        p2 = tuple(pts[j])\n",
    "        rr = line_nd(p1, p2, endpoint=True)\n",
    "        bridge[rr] = True\n",
    "        used[i] = True\n",
    "        used[j] = True\n",
    "\n",
    "    if not bridge.any():\n",
    "        return neuron_mask\n",
    "\n",
    "    bridged = neuron_mask | binary_dilation(bridge, ball(int(bridge_dilate_radius_vox)))\n",
    "    bridged = binary_closing(bridged, ball(1))\n",
    "    return bridged\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Helper: refine radii by distance transform\n",
    "# ===============================\n",
    "def refine_radii_via_dt(img3d, blobs, win_px=40, bin_method=\"sauvola\"):\n",
    "    from skimage.filters import threshold_sauvola, threshold_local, threshold_otsu\n",
    "    from skimage.morphology import remove_small_objects, disk, binary_opening\n",
    "    from skimage.measure import label as _label\n",
    "    from scipy.ndimage import distance_transform_edt as _edt\n",
    "\n",
    "    if blobs is None or len(blobs) == 0:\n",
    "        return blobs\n",
    "\n",
    "    Z, H, W = img3d.shape\n",
    "    out = blobs.copy().astype(np.float32)\n",
    "\n",
    "    for i, (zc, yc, xc, _) in enumerate(out):\n",
    "        z, y, x = int(round(zc)), int(round(yc)), int(round(xc))\n",
    "        if not (0 <= z < Z and 0 <= y < H and 0 <= x < W):\n",
    "            continue\n",
    "\n",
    "        y1, y2 = max(0, y - win_px), min(H, y + win_px + 1)\n",
    "        x1, x2 = max(0, x - win_px), min(W, x + win_px + 1)\n",
    "        patch = img3d[z, y1:y2, x1:x2]\n",
    "\n",
    "        if bin_method == \"sauvola\":\n",
    "            ws = max(11, 2 * (win_px // 2) + 1)\n",
    "            thr = threshold_sauvola(patch, window_size=ws, k=0.4)\n",
    "            bw = patch > thr\n",
    "        elif bin_method == \"local\":\n",
    "            ws = max(11, 2 * (win_px // 2) + 1)\n",
    "            thr = threshold_local(patch, block_size=ws, offset=-0.4 * np.std(patch))\n",
    "            bw = patch > thr\n",
    "        else:\n",
    "            try:\n",
    "                thr = threshold_otsu(patch)\n",
    "                bw = patch > thr\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        bw = binary_opening(bw, footprint=disk(1))\n",
    "        bw = remove_small_objects(bw, min_size=3, connectivity=2)\n",
    "\n",
    "        yy, xx = y - y1, x - x1\n",
    "        if not (0 <= yy < bw.shape[0] and 0 <= xx < bw.shape[1]) or not bw[yy, xx]:\n",
    "            continue\n",
    "\n",
    "        lab = _label(bw)\n",
    "        lbl = lab[yy, xx]\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "        bw_obj = (lab == lbl)\n",
    "        dt = _edt(bw_obj)\n",
    "        r_px = float(dt[yy, xx])\n",
    "        if r_px <= 0:\n",
    "            continue\n",
    "        out[i, 3] = r_px\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def refine_radii_via_radial_intensity(\n",
    "    img3d,\n",
    "    blobs,\n",
    "    vx_um,\n",
    "    vy_um,\n",
    "    vz_um,\n",
    "    max_radius_nm=300.0,\n",
    "    dr_nm=10.0,\n",
    "    min_drop_fraction=0.5,\n",
    "):\n",
    "    if blobs is None or len(blobs) == 0:\n",
    "        return blobs\n",
    "\n",
    "    img = img3d.astype(np.float32)\n",
    "    Z, Y, X = img.shape\n",
    "    blobs_out = blobs.copy().astype(np.float32)\n",
    "\n",
    "    max_r_um = max_radius_nm / 1000.0\n",
    "    dr_um = dr_nm / 1000.0\n",
    "\n",
    "    r_edges = np.arange(0.0, max_r_um + dr_um, dr_um)\n",
    "    if r_edges.size < 2:\n",
    "        return blobs_out\n",
    "    r_centers = 0.5 * (r_edges[:-1] + r_edges[1:])\n",
    "\n",
    "    px_um_xy = float(np.sqrt(vx_um * vy_um))\n",
    "\n",
    "    for i, (zc, yc, xc, r_px_init) in enumerate(blobs_out):\n",
    "        z0 = int(round(zc))\n",
    "        y0 = int(round(yc))\n",
    "        x0 = int(round(xc))\n",
    "\n",
    "        if not (0 <= z0 < Z and 0 <= y0 < Y and 0 <= x0 < X):\n",
    "            continue\n",
    "\n",
    "        rz = max(1, int(np.ceil(max_r_um / vz_um)))\n",
    "        ry = max(1, int(np.ceil(max_r_um / vy_um)))\n",
    "        rx = max(1, int(np.ceil(max_r_um / vx_um)))\n",
    "\n",
    "        z1, z2 = max(0, z0 - rz), min(Z, z0 + rz + 1)\n",
    "        y1, y2 = max(0, y0 - ry), min(Y, y0 + ry + 1)\n",
    "        x1, x2 = max(0, x0 - rx), min(X, x0 + rx + 1)\n",
    "        if z1 >= z2 or y1 >= y2 or x1 >= x2:\n",
    "            continue\n",
    "\n",
    "        patch = img[z1:z2, y1:y2, x1:x2]\n",
    "\n",
    "        zz, yy, xx = np.mgrid[z1:z2, y1:y2, x1:x2]\n",
    "        dz_um = (zz - z0) * vz_um\n",
    "        dy_um = (yy - y0) * vy_um\n",
    "        dx_um = (xx - x0) * vx_um\n",
    "        r_um = np.sqrt(dz_um**2 + dy_um**2 + dx_um**2)\n",
    "\n",
    "        mask = (r_um <= max_r_um)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        r_vals = r_um[mask].ravel()\n",
    "        I_vals = patch[mask].ravel()\n",
    "\n",
    "        bin_idx = np.digitize(r_vals, r_edges) - 1\n",
    "        valid = (bin_idx >= 0) & (bin_idx < r_centers.size)\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "\n",
    "        bin_idx = bin_idx[valid]\n",
    "        I_vals = I_vals[valid]\n",
    "\n",
    "        sums = np.bincount(bin_idx, weights=I_vals, minlength=r_centers.size)\n",
    "        counts = np.bincount(bin_idx, minlength=r_centers.size)\n",
    "        with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "            prof = sums / np.maximum(counts, 1)\n",
    "\n",
    "        have = counts > 0\n",
    "        if not np.any(have):\n",
    "            continue\n",
    "\n",
    "        r_prof = r_centers[have]\n",
    "        I_prof = prof[have].astype(np.float32)\n",
    "\n",
    "        I_smooth = gaussian_filter1d(I_prof, sigma=1.0)\n",
    "        I_max = float(I_smooth.max())\n",
    "        if I_max <= 0:\n",
    "            continue\n",
    "        I_min = float(I_smooth.min())\n",
    "\n",
    "        if (I_max - I_min) / max(I_max, 1e-9) < min_drop_fraction:\n",
    "            continue\n",
    "\n",
    "        I_half = I_min + 0.5 * (I_max - I_min)\n",
    "\n",
    "        peak_idx = int(np.argmax(I_smooth))\n",
    "        n_bins = len(I_smooth)\n",
    "\n",
    "        left_idx = peak_idx\n",
    "        while left_idx > 0 and I_smooth[left_idx] >= I_half:\n",
    "            left_idx -= 1\n",
    "        if left_idx < peak_idx and I_smooth[left_idx] < I_half:\n",
    "            left_idx += 1\n",
    "\n",
    "        right_idx = peak_idx\n",
    "        while right_idx < n_bins - 1 and I_smooth[right_idx] >= I_half:\n",
    "            right_idx += 1\n",
    "        if right_idx > peak_idx and I_smooth[right_idx] < I_half:\n",
    "            right_idx -= 1\n",
    "\n",
    "        if right_idx <= left_idx:\n",
    "            continue\n",
    "\n",
    "        radius_um = 0.5 * (float(r_prof[right_idx]) - float(r_prof[left_idx]))\n",
    "        if radius_um <= 0:\n",
    "            continue\n",
    "\n",
    "        r_fwhm_px = radius_um / max(px_um_xy, 1e-9)\n",
    "        blobs_out[i, 3] = max(float(r_px_init), float(r_fwhm_px))\n",
    "\n",
    "    return blobs_out\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Distance/overlap-aware classification helpers\n",
    "# ===============================\n",
    "\n",
    "def nearest_cell_label(cell_seg, z, y, x, max_r=12):\n",
    "    Z, Y, X = cell_seg.shape\n",
    "    for r in range(1, max_r + 1):\n",
    "        z1, z2 = max(0, z - r), min(Z, z + r + 1)\n",
    "        y1, y2 = max(0, y - r), min(Y, y + r + 1)\n",
    "        x1, x2 = max(0, x - r), min(X, x + r + 1)\n",
    "        patch = cell_seg[z1:z2, y1:y2, x1:x2]\n",
    "        lab = patch[patch > 0]\n",
    "        if lab.size:\n",
    "            return int(np.bincount(lab.ravel()).argmax())\n",
    "    return 0\n",
    "\n",
    "\n",
    "def sphere_overlap_fraction(zc_um, yc_um, xc_um, r_um, mask_bool, vx_um, vy_um, vz_um):\n",
    "    if r_um <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    zc = int(round(zc_um / vz_um))\n",
    "    yc = int(round(yc_um / vy_um))\n",
    "    xc = int(round(xc_um / vx_um))\n",
    "\n",
    "    rz = max(1, int(np.ceil(r_um / vz_um)))\n",
    "    ry = max(1, int(np.ceil(r_um / vy_um)))\n",
    "    rx = max(1, int(np.ceil(r_um / vx_um)))\n",
    "\n",
    "    Z, Y, X = mask_bool.shape\n",
    "    z1, z2 = max(0, zc - rz), min(Z, zc + rz + 1)\n",
    "    y1, y2 = max(0, yc - ry), min(Y, yc + ry + 1)\n",
    "    x1, x2 = max(0, xc - rx), min(X, xc + rx + 1)\n",
    "    if z1 >= z2 or y1 >= y2 or x1 >= x2:\n",
    "        return 0.0\n",
    "\n",
    "    zz, yy, xx = np.mgrid[z1:z2, y1:y2, x1:x2]\n",
    "    dz = (zz - zc) * vz_um\n",
    "    dy = (yy - yc) * vy_um\n",
    "    dx = (xx - xc) * vx_um\n",
    "    sphere = (dz*dz + dy*dy + dx*dx) <= (r_um * r_um)\n",
    "\n",
    "    if not np.any(sphere):\n",
    "        return 0.0\n",
    "\n",
    "    in_mask = mask_bool[z1:z2, y1:y2, x1:x2] & sphere\n",
    "    return float(in_mask.sum()) / float(sphere.sum())\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Full-size overlay exporter (RGB stack + MP4)\n",
    "# ===============================\n",
    "def _norm_u8_stack(vol):\n",
    "    vmin, vmax = float(vol.min()), float(vol.max())\n",
    "    if vmax > vmin:\n",
    "        out = (np.clip((vol - vmin) / (vmax - vmin), 0, 1) * 255.0).astype(np.uint8)\n",
    "    else:\n",
    "        out = np.zeros_like(vol, dtype=np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def make_label_colormap(n_labels, seed_hue=0.13):\n",
    "    colors = np.zeros((n_labels + 1, 3), dtype=np.uint8)\n",
    "    if n_labels <= 0:\n",
    "        return colors\n",
    "    for i in range(1, n_labels + 1):\n",
    "        h = (seed_hue + (i - 1) / max(n_labels, 1)) % 1.0\n",
    "        s = 1.0\n",
    "        v = 1.0\n",
    "        r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "        colors[i] = (int(255 * r), int(255 * g), int(255 * b))\n",
    "    return colors\n",
    "\n",
    "\n",
    "def export_fullsize_overlay_stack(\n",
    "    img_ch1,\n",
    "    img_ch2_raw,\n",
    "    cell_seg_viz,\n",
    "    df,\n",
    "    vx_um, vy_um, vz_um,\n",
    "    output_dir,\n",
    "    alpha_labels=0.45,\n",
    "    draw_only_inside=True,\n",
    "    fps=8,\n",
    "    basename=\"FULLSIZE_overlay_ID_Lysosomes_MAGENTA\",\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    ch1_u8 = _norm_u8_stack(img_ch1.astype(np.float32))\n",
    "    ch2_u8 = _norm_u8_stack(img_ch2_raw.astype(np.float32))\n",
    "\n",
    "    Z, H, W = ch2_u8.shape\n",
    "    n_labels = int(cell_seg_viz.max()) if isinstance(cell_seg_viz, np.ndarray) else 0\n",
    "    cmap = make_label_colormap(n_labels, seed_hue=0.13)\n",
    "\n",
    "    use_df = None\n",
    "    if isinstance(df, pd.DataFrame) and len(df) > 0 and {\"z_um\", \"y_um\", \"x_um\", \"radius_um\"}.issubset(df.columns):\n",
    "        if draw_only_inside and \"location_ch2\" in df.columns:\n",
    "            use_df = df[df[\"location_ch2\"] == \"cell\"].copy()\n",
    "        else:\n",
    "            use_df = df.copy()\n",
    "        use_df = use_df[\n",
    "            np.isfinite(use_df[\"z_um\"]) &\n",
    "            np.isfinite(use_df[\"y_um\"]) &\n",
    "            np.isfinite(use_df[\"x_um\"]) &\n",
    "            np.isfinite(use_df[\"radius_um\"])\n",
    "        ].copy()\n",
    "\n",
    "    px_um_xy = float(np.sqrt(vx_um * vy_um))\n",
    "    frames = np.zeros((Z, H, W, 3), dtype=np.uint8)\n",
    "\n",
    "    for z in range(Z):\n",
    "        base = np.dstack([ch1_u8[z], ch2_u8[z], ch1_u8[z]]).astype(np.float32)\n",
    "\n",
    "        lab2d = cell_seg_viz[z].astype(np.int32)\n",
    "        lab_rgb = cmap[lab2d].astype(np.float32)\n",
    "\n",
    "        mask = (lab2d > 0)[..., None].astype(np.float32)\n",
    "        out = base * (1.0 - alpha_labels * mask) + lab_rgb * (alpha_labels * mask)\n",
    "\n",
    "        if use_df is not None and len(use_df) > 0:\n",
    "            zc = (use_df[\"z_um\"].to_numpy() / vz_um).astype(float)\n",
    "            yc = (use_df[\"y_um\"].to_numpy() / vy_um).astype(float)\n",
    "            xc = (use_df[\"x_um\"].to_numpy() / vx_um).astype(float)\n",
    "            r_um = use_df[\"radius_um\"].to_numpy().astype(float)\n",
    "\n",
    "            dz_um = np.abs(zc - z) * vz_um\n",
    "            hits = dz_um <= r_um\n",
    "            if np.any(hits):\n",
    "                r_proj_um = np.sqrt(np.clip(r_um[hits]**2 - dz_um[hits]**2, 0.0, None))\n",
    "                r_proj_px = r_proj_um / max(px_um_xy, 1e-12)\n",
    "                ys = np.rint(yc[hits]).astype(int)\n",
    "                xs = np.rint(xc[hits]).astype(int)\n",
    "\n",
    "                out_u8 = np.clip(out, 0, 255).astype(np.uint8)\n",
    "                for y, x, rp in zip(ys, xs, r_proj_px):\n",
    "                    rr = int(max(3, round(rp)))\n",
    "                    if 0 <= y < H and 0 <= x < W and rr > 0:\n",
    "                        cv2.circle(out_u8, (x, y), rr, LYS_EDGE_BGR, 4, lineType=cv2.LINE_AA)\n",
    "                        cv2.circle(out_u8, (x, y), rr, LYS_MAGENTA_BGR, 2, lineType=cv2.LINE_AA)\n",
    "                        cv2.circle(out_u8, (x, y), 1,  LYS_MAGENTA_BGR, -1, lineType=cv2.LINE_AA)\n",
    "                out = out_u8.astype(np.float32)\n",
    "\n",
    "        frames[z] = np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "    tiff_path = os.path.join(output_dir, f\"{basename}.tif\")\n",
    "    tiff.imwrite(tiff_path, frames, photometric=\"rgb\")\n",
    "    print(\"Saved full-size RGB TIFF stack:\", tiff_path)\n",
    "\n",
    "    mp4_path = os.path.join(output_dir, f\"{basename}.mp4\")\n",
    "    try:\n",
    "        with imageio.get_writer(\n",
    "            mp4_path,\n",
    "            fps=int(fps),\n",
    "            format=\"FFMPEG\",\n",
    "            codec=\"libx264\",\n",
    "            macro_block_size=None\n",
    "        ) as w:\n",
    "            for fr in frames:\n",
    "                w.append_data(fr)\n",
    "        print(\"Saved full-size MP4:\", mp4_path)\n",
    "    except Exception as e:\n",
    "        gif_path = os.path.join(output_dir, f\"{basename}.gif\")\n",
    "        imageio.mimsave(gif_path, list(frames), fps=int(fps))\n",
    "        print(\"FFMPEG failed, saved GIF instead:\", gif_path, \"Error:\", e)\n",
    "\n",
    "    return tiff_path, mp4_path\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MAIN\n",
    "# ===============================\n",
    "DEFAULT_VX_VY_UM = 0.04\n",
    "DEFAULT_VZ_UM = None\n",
    "\n",
    "cfg = get_user_config_gui(\n",
    "    default_vxy_um=DEFAULT_VX_VY_UM,\n",
    "    default_vz_um=DEFAULT_VZ_UM,\n",
    "    default_erode_mult=1.0,\n",
    "    default_blob_threshold=0.001,\n",
    "    default_diam_min_um=0.0,\n",
    "    default_diam_max_um=\"\",\n",
    ")\n",
    "\n",
    "file_path = cfg[\"file_path\"]\n",
    "output_dir = cfg[\"output_dir\"]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.chdir(output_dir)\n",
    "\n",
    "print(\"Selected file:\", file_path)\n",
    "print(\"Outputs will be saved to:\", output_dir)\n",
    "\n",
    "ERODE_MULT = cfg[\"ERODE_MULT\"]\n",
    "BLOB_THRESHOLD = cfg[\"BLOB_THRESHOLD\"]\n",
    "\n",
    "MAX_REASONABLE_VXY_UM = cfg[\"MAX_REASONABLE_VXY_UM\"]\n",
    "MARGIN_UM = cfg[\"MARGIN_UM\"]\n",
    "OVERLAP_ALPHA = cfg[\"OVERLAP_ALPHA\"]\n",
    "NEIGHBOR_MAX_VOX = cfg[\"NEIGHBOR_MAX_VOX\"]\n",
    "VIZ_MIN_VOXELS = cfg[\"VIZ_MIN_VOXELS\"]\n",
    "\n",
    "# >>> NEW: advanced GUI params\n",
    "MAX_GAP_UM = cfg[\"MAX_GAP_UM\"]\n",
    "CLOSING_RADIUS_VOX = cfg[\"CLOSING_RADIUS_VOX\"]\n",
    "\n",
    "CH1_SMOOTH_SIGMA = cfg[\"CH1_SMOOTH_SIGMA\"]\n",
    "BLOB_MIN_SIGMA = cfg[\"BLOB_MIN_SIGMA\"]\n",
    "BLOB_MAX_SIGMA = cfg[\"BLOB_MAX_SIGMA\"]\n",
    "BLOB_NUM_SIGMA = cfg[\"BLOB_NUM_SIGMA\"]\n",
    "\n",
    "RADIAL_MAX_RADIUS_NM = cfg[\"RADIAL_MAX_RADIUS_NM\"]\n",
    "RADIAL_DR_NM = cfg[\"RADIAL_DR_NM\"]\n",
    "RADIAL_MIN_DROP_FRACTION = cfg[\"RADIAL_MIN_DROP_FRACTION\"]\n",
    "\n",
    "CH2_SMOOTH_SIGMA = cfg[\"CH2_SMOOTH_SIGMA\"]\n",
    "THRESH_BLOCK_SIZE = cfg[\"THRESH_BLOCK_SIZE\"]\n",
    "THRESH_OFFSET_STD_MULT = cfg[\"THRESH_OFFSET_STD_MULT\"]\n",
    "\n",
    "FPS = cfg[\"VIDEO_FPS\"]\n",
    "LAUNCH_VIEWER = cfg[\"LAUNCH_VIEWER\"]\n",
    "GENERATE_VIDEOS = cfg[\"GENERATE_VIDEOS\"]\n",
    "\n",
    "# >>> NEW: chosen interval from GUI\n",
    "DIAMETER_MIN_UM = float(cfg.get(\"DIAMETER_MIN_UM\", 0.0))\n",
    "DIAMETER_MAX_UM = cfg.get(\"DIAMETER_MAX_UM\", None)  # None = no max\n",
    "\n",
    "# Load data + metadata\n",
    "img_ch1, img_ch2, (vx_um, vy_um, vz_um), meta = load_any(file_path)\n",
    "print(f\"[metadata] vx_um={vx_um}  vy_um={vy_um}  vz_um={vz_um}\")\n",
    "\n",
    "def _prompt_missing_size(title, prompt, default_value):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    try:\n",
    "        root.attributes(\"-topmost\", True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    use_default = messagebox.askyesno(\n",
    "        title,\n",
    "        f\"{prompt}\\n\\nUse default value: {default_value} ?\"\n",
    "    )\n",
    "    if use_default:\n",
    "        root.destroy()\n",
    "        return float(default_value)\n",
    "\n",
    "    val = simpledialog.askfloat(\n",
    "        title,\n",
    "        \"Enter a new value:\",\n",
    "        initialvalue=float(default_value),\n",
    "        minvalue=1e-12\n",
    "    )\n",
    "    root.destroy()\n",
    "    if val is None:\n",
    "        raise SystemExit(\"Cancelled.\")\n",
    "    return float(val)\n",
    "\n",
    "# XY\n",
    "if vx_um is None or vy_um is None:\n",
    "    vx_um = vy_um = _prompt_missing_size(\n",
    "        title=\"Missing metadata\",\n",
    "        prompt=\"XY pixel size metadata is missing (µm/px).\",\n",
    "        default_value=float(cfg[\"DEFAULT_VX_VY_UM\"]),\n",
    "    )\n",
    "\n",
    "# Z\n",
    "if vz_um is None:\n",
    "    z_default = float(cfg[\"DEFAULT_VZ_UM\"]) if (cfg[\"DEFAULT_VZ_UM\"] is not None) else float(vx_um)\n",
    "    vz_um = _prompt_missing_size(\n",
    "        title=\"Missing metadata\",\n",
    "        prompt=\"Z step metadata is missing (µm/slice).\",\n",
    "        default_value=z_default,\n",
    "    )\n",
    "\n",
    "if vx_um > MAX_REASONABLE_VXY_UM:\n",
    "    raise ValueError(f\"XY pixel size too large: {vx_um} µm/px\")\n",
    "\n",
    "px_um_xy = float(np.sqrt(vx_um * vy_um))\n",
    "px_um = px_um_xy * 0.55\n",
    "voxel_um3 = vx_um * vy_um * vz_um\n",
    "print(f\"Voxel size (µm): X={vx_um}, Y={vy_um}, Z={vz_um}\")\n",
    "\n",
    "# ===== Aliases =====\n",
    "image = img_ch1\n",
    "image_2 = img_ch2\n",
    "\n",
    "# ==========================================\n",
    "# Lysosome detection (Ch1)\n",
    "# ==========================================\n",
    "image_smooth = gaussian(image, sigma=CH1_SMOOTH_SIGMA)\n",
    "\n",
    "blobs = blob_log(\n",
    "    image_smooth,\n",
    "    min_sigma=BLOB_MIN_SIGMA,\n",
    "    max_sigma=BLOB_MAX_SIGMA,\n",
    "    num_sigma=BLOB_NUM_SIGMA,\n",
    "    threshold=BLOB_THRESHOLD\n",
    ")\n",
    "\n",
    "if len(blobs) > 0:\n",
    "    blobs[:, 3] *= np.sqrt(3)  # LoG radius correction (pixels)\n",
    "    blobs = refine_radii_via_dt(image_smooth, blobs)\n",
    "    blobs = refine_radii_via_radial_intensity(\n",
    "        image_smooth,\n",
    "        blobs,\n",
    "        vx_um, vy_um, vz_um,\n",
    "        max_radius_nm=RADIAL_MAX_RADIUS_NM,\n",
    "        dr_nm=RADIAL_DR_NM,\n",
    "        min_drop_fraction=RADIAL_MIN_DROP_FRACTION\n",
    "    )\n",
    "\n",
    "# Peak intensity in raw 16-bit Ch1\n",
    "peak_gray = np.zeros(len(blobs), dtype=np.uint16)\n",
    "Z0, Y0, X0 = image.shape\n",
    "rad = 1\n",
    "\n",
    "for i, (zc, yc, xc, _) in enumerate(blobs):\n",
    "    zc_i = int(round(zc))\n",
    "    yc_i = int(round(yc))\n",
    "    xc_i = int(round(xc))\n",
    "\n",
    "    z1, z2 = max(0, zc_i - rad), min(Z0, zc_i + rad + 1)\n",
    "    y1, y2 = max(0, yc_i - rad), min(Y0, yc_i + rad + 1)\n",
    "    x1, x2 = max(0, xc_i - rad), min(X0, xc_i + rad + 1)\n",
    "\n",
    "    peak_gray[i] = np.max(image[z1:z2, y1:y2, x1:x2]).astype(np.uint16)\n",
    "\n",
    "if len(blobs) > 0:\n",
    "    z_um = blobs[:, 0] * vz_um\n",
    "    y_um = blobs[:, 1] * vy_um\n",
    "    x_um = blobs[:, 2] * vx_um\n",
    "    radius_um = blobs[:, 3] * px_um\n",
    "    diameter_um = 2 * radius_um\n",
    "    volume_um3 = (4/3) * np.pi * radius_um**3\n",
    "    blob_ids = np.arange(1, len(blobs) + 1, dtype=int)\n",
    "else:\n",
    "    z_um = y_um = x_um = radius_um = diameter_um = volume_um3 = np.array([])\n",
    "    blob_ids = np.array([], dtype=int)\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    \"id\": blob_ids,\n",
    "    \"z_um\": z_um,\n",
    "    \"y_um\": y_um,\n",
    "    \"x_um\": x_um,\n",
    "    \"radius_um\": radius_um,\n",
    "    \"diameter_um\": diameter_um,\n",
    "    \"volume_um3\": volume_um3,\n",
    "    \"peak_gray\": peak_gray,\n",
    "})\n",
    "\n",
    "# >>> NEW: apply the chosen diameter interval BEFORE saving & BEFORE everything else\n",
    "dmax_eff = np.inf if (DIAMETER_MAX_UM is None) else float(DIAMETER_MAX_UM)\n",
    "if len(df_all) > 0:\n",
    "    dd = df_all[\"diameter_um\"].to_numpy(dtype=float)\n",
    "    keep = np.isfinite(dd) & (dd >= float(DIAMETER_MIN_UM)) & (dd <= dmax_eff)\n",
    "    df = df_all.loc[keep].copy()\n",
    "else:\n",
    "    df = df_all.copy()\n",
    "\n",
    "# Save full + filtered (so you can debug if needed)\n",
    "df_all.to_csv(\"lysosome_blobs_regions_ALL.csv\", index=False)\n",
    "df.to_csv(\"lysosome_blobs_regions.csv\", index=False)\n",
    "print(\"Saved: lysosome_blobs_regions_ALL.csv (all) and lysosome_blobs_regions.csv (filtered)\")\n",
    "\n",
    "# For downstream drawing: DO NOT fallback-draw raw blobs if filtering removed everything\n",
    "ALLOW_BLOB_FALLBACK = (len(df_all) == 0)\n",
    "\n",
    "# ==========================================\n",
    "# CH2 segmentation (neurites mask)\n",
    "# ==========================================\n",
    "vol = image_2.astype(np.float32)\n",
    "vmin, vmax = float(vol.min()), float(vol.max())\n",
    "if vmax > vmin:\n",
    "    vol = (vol - vmin) / (vmax - vmin)\n",
    "else:\n",
    "    vol[:] = 0.0\n",
    "\n",
    "ch2 = gaussian(vol, sigma=CH2_SMOOTH_SIGMA, preserve_range=True)\n",
    "\n",
    "neuron_mask = np.zeros_like(ch2, dtype=bool)\n",
    "for z in range(ch2.shape[0]):\n",
    "    R = ch2[z]\n",
    "    t = threshold_local(R, block_size=THRESH_BLOCK_SIZE, offset=-THRESH_OFFSET_STD_MULT * np.std(R))\n",
    "    neuron_mask[z] = R > t\n",
    "\n",
    "if NEURITE_MODE:\n",
    "    neuron_mask = binary_closing(neuron_mask, ball(int(CLOSING_RADIUS_VOX)))  # <-- your existing\n",
    "    neuron_mask = remove_small_objects(neuron_mask, min_size=30, connectivity=3)\n",
    "\n",
    "    neuron_mask = stitch_neurite_fragments_by_orientation(\n",
    "        neuron_mask,\n",
    "        vx_um=vx_um, vy_um=vy_um, vz_um=vz_um,\n",
    "        max_gap_um=float(MAX_GAP_UM),\n",
    "        cos_min=0.6,\n",
    "        bridge_dilate_radius_vox=1,\n",
    "    )\n",
    "\n",
    "    neuron_mask = remove_small_objects(neuron_mask, min_size=200, connectivity=3)\n",
    "else:\n",
    "    neuron_mask = binary_fill_holes(neuron_mask)\n",
    "\n",
    "print(\"neurite voxels:\", int(neuron_mask.sum()))\n",
    "\n",
    "# === NEW (B2): export AUTO mask so you can edit it in Napari and re-run ===\n",
    "tiff.imwrite(\"neuron_mask_AUTO.tif\", (neuron_mask.astype(np.uint8) * 255))\n",
    "print(\"Saved: neuron_mask_AUTO.tif (open in Napari, edit connections, then save as neuron_mask_edited.tif)\")\n",
    "\n",
    "# ---- ID segmentation ----\n",
    "if NEURITE_MODE:\n",
    "\n",
    "    # === NEW (B2): if an edited mask exists, use it instead of AUTO mask ===\n",
    "    if USE_EDITED_MASK_IF_EXISTS and os.path.isfile(EDITED_MASK_PATH):\n",
    "        m = tiff.imread(EDITED_MASK_PATH)\n",
    "        m = np.squeeze(m)  # just in case\n",
    "        if m.shape != neuron_mask.shape:\n",
    "            raise ValueError(f\"Edited mask shape {m.shape} != expected {neuron_mask.shape}\")\n",
    "        neuron_mask = (m > 0)\n",
    "        print(f\"Using edited mask: {EDITED_MASK_PATH}\")\n",
    "\n",
    "    cell_seg = label(neuron_mask, connectivity=3).astype(np.int32)\n",
    "    cell_mask = neuron_mask.copy()\n",
    "    print(\"Detected components (neurite networks):\", int(cell_seg.max()))\n",
    "else:\n",
    "    dist = edt(neuron_mask)\n",
    "    cell_min_radius_vox = 1\n",
    "    cell_mask = (dist >= cell_min_radius_vox)\n",
    "    cell_mask &= neuron_mask\n",
    "    cell_mask = binary_fill_holes(binary_closing(binary_opening(cell_mask, ball(1)), ball(2)))\n",
    "\n",
    "    body_lab = label(cell_mask, connectivity=3)\n",
    "    n_cells = int(body_lab.max())\n",
    "    print(f\"Detected {n_cells} cells (soma).\")\n",
    "\n",
    "    if n_cells > 0:\n",
    "        dist_inside = edt(neuron_mask)\n",
    "        cell_seg = watershed(-dist_inside, markers=body_lab, mask=neuron_mask)\n",
    "    else:\n",
    "        cell_seg = np.zeros_like(neuron_mask, dtype=np.int32)\n",
    "\n",
    "print(\"ID voxels:\", int((cell_seg > 0).sum()))\n",
    "\n",
    "# ==========================================\n",
    "# Visualization-only filtering (hide tiny components) + serial IDs\n",
    "# ==========================================\n",
    "cell_seg_viz = cell_seg.copy()\n",
    "cell_id_map_viz = {}\n",
    "\n",
    "if isinstance(cell_seg_viz, np.ndarray) and cell_seg_viz.max() > 0:\n",
    "    counts_viz = np.bincount(cell_seg_viz.ravel().astype(np.int64))\n",
    "    tiny_labels = np.where(counts_viz < VIZ_MIN_VOXELS)[0]\n",
    "    tiny_labels = tiny_labels[tiny_labels > 0]\n",
    "    if tiny_labels.size > 0:\n",
    "        tiny_mask = np.isin(cell_seg_viz, tiny_labels)\n",
    "        cell_seg_viz[tiny_mask] = 0\n",
    "\n",
    "    unique_labels = np.unique(cell_seg_viz)\n",
    "    unique_labels = unique_labels[unique_labels > 0]\n",
    "\n",
    "    if unique_labels.size > 0:\n",
    "        new_seg = np.zeros_like(cell_seg_viz, dtype=np.int32)\n",
    "        for new_id, old_id in enumerate(unique_labels, start=1):\n",
    "            new_seg[cell_seg_viz == old_id] = new_id\n",
    "            cell_id_map_viz[old_id] = new_id\n",
    "        cell_seg_viz = new_seg\n",
    "\n",
    "cell_mask_viz = (cell_seg_viz > 0)\n",
    "\n",
    "# ==========================================\n",
    "# Classify lysosomes (FILTERED df): inside vs outside neurite mask, and assign ID\n",
    "# ==========================================\n",
    "dist_out_um = _edt(~neuron_mask, sampling=(vz_um, vy_um, vx_um)).astype(np.float32)\n",
    "soft_cell_mask = neuron_mask | (dist_out_um <= MARGIN_UM)\n",
    "\n",
    "location_ch2 = []\n",
    "cell_id_list = []\n",
    "\n",
    "if len(df) > 0:\n",
    "    Z, Y, X = neuron_mask.shape\n",
    "    for (zc_um, yc_um, xc_um, r_um) in df[[\"z_um\", \"y_um\", \"x_um\", \"radius_um\"]].to_numpy():\n",
    "        zz = int(round(zc_um / vz_um))\n",
    "        yy = int(round(yc_um / vy_um))\n",
    "        xx = int(round(xc_um / vx_um))\n",
    "\n",
    "        inside_hard = (0 <= zz < Z and 0 <= yy < Y and 0 <= xx < X and neuron_mask[zz, yy, xx])\n",
    "        inside_soft = (0 <= zz < Z and 0 <= yy < Y and 0 <= xx < X and soft_cell_mask[zz, yy, xx])\n",
    "\n",
    "        is_inside = bool(inside_hard)\n",
    "        if not is_inside and inside_soft:\n",
    "            is_inside = True\n",
    "\n",
    "        if not is_inside:\n",
    "            frac = sphere_overlap_fraction(zc_um, yc_um, xc_um, r_um, neuron_mask, vx_um, vy_um, vz_um)\n",
    "            if frac >= OVERLAP_ALPHA:\n",
    "                is_inside = True\n",
    "\n",
    "        if is_inside:\n",
    "            cid = 0\n",
    "            if 0 <= zz < Z and 0 <= yy < Y and 0 <= xx < X:\n",
    "                if cell_seg[zz, yy, xx] != 0:\n",
    "                    cid = int(cell_seg[zz, yy, xx])\n",
    "                else:\n",
    "                    cid = nearest_cell_label(cell_seg, zz, yy, xx, max_r=NEIGHBOR_MAX_VOX)\n",
    "            location_ch2.append(\"cell\")\n",
    "            cell_id_list.append(cid)\n",
    "        else:\n",
    "            location_ch2.append(\"outside\")\n",
    "            cell_id_list.append(0)\n",
    "\n",
    "    df[\"location_ch2\"] = location_ch2\n",
    "    df[\"cell_id_ch2\"] = cell_id_list\n",
    "    df[\"cell_id_ch2_viz\"] = df[\"cell_id_ch2\"].map(cell_id_map_viz).fillna(0).astype(int) if isinstance(cell_id_map_viz, dict) else 0\n",
    "\n",
    "    # Serial lysosome IDs within each ID component (filtered set)\n",
    "    df[\"lys_id_in_cell\"] = 0\n",
    "    mask_in = (df[\"location_ch2\"] == \"cell\") & (df[\"cell_id_ch2\"] > 0)\n",
    "    df_sorted = df.loc[mask_in].sort_values([\"cell_id_ch2\", \"z_um\", \"y_um\", \"x_um\"]).copy()\n",
    "    df.loc[df_sorted.index, \"lys_id_in_cell\"] = (df_sorted.groupby(\"cell_id_ch2\").cumcount().to_numpy() + 1).astype(int)\n",
    "\n",
    "    df.to_csv(\"lysosomes_with_cell_vs_outside.csv\", index=False)\n",
    "    print(\"Saved: lysosomes_with_cell_vs_outside.csv (filtered)\")\n",
    "\n",
    "    df.groupby(\"location_ch2\").size().reset_index(name=\"count\").to_csv(\"lysosome_counts_cell_vs_outside.csv\", index=False)\n",
    "    (df[df[\"location_ch2\"] == \"cell\"]\n",
    "        .groupby(\"cell_id_ch2\").size()\n",
    "        .reset_index(name=\"count\")\n",
    "        .to_csv(\"lysosome_counts_by_cell.csv\", index=False))\n",
    "    print(\"Saved: lysosome_counts_cell_vs_outside.csv, lysosome_counts_by_cell.csv (filtered)\")\n",
    "\n",
    "# Per-ID volumes (µm^3) (independent of filtering)\n",
    "cell_volume_df = pd.DataFrame(columns=[\"cell_id_ch2\", \"voxel_count\", \"volume_um3\"])\n",
    "if isinstance(cell_seg, np.ndarray) and cell_seg.max() > 0:\n",
    "    counts = np.bincount(cell_seg.ravel().astype(np.int64))\n",
    "    cell_ids = np.arange(1, counts.size, dtype=int)\n",
    "    voxels = counts[1:].astype(np.int64)\n",
    "    vol_um3 = voxels.astype(float) * voxel_um3\n",
    "\n",
    "    cell_volume_df = pd.DataFrame({\n",
    "        \"cell_id_ch2\": cell_ids,\n",
    "        \"voxel_count\": voxels,\n",
    "        \"volume_um3\": vol_um3\n",
    "    })\n",
    "    cell_volume_df.to_csv(\"cell_volumes_ch2.csv\", index=False)\n",
    "    print(\"Saved: cell_volumes_ch2.csv\")\n",
    "\n",
    "    # Merge with lysosome counts (filtered)\n",
    "    try:\n",
    "        if len(df) > 0 and \"location_ch2\" in df and \"cell_id_ch2\" in df:\n",
    "            lys_counts = (\n",
    "                df[df[\"location_ch2\"] == \"cell\"]\n",
    "                .groupby(\"cell_id_ch2\").size()\n",
    "                .reset_index(name=\"lysosome_count\")\n",
    "            )\n",
    "        else:\n",
    "            lys_counts = pd.DataFrame(columns=[\"cell_id_ch2\", \"lysosome_count\"])\n",
    "\n",
    "        merged = cell_volume_df.merge(lys_counts, on=\"cell_id_ch2\", how=\"left\").fillna({\"lysosome_count\": 0})\n",
    "        merged.to_csv(\"cell_metrics_ch2.csv\", index=False)\n",
    "        print(\"Saved: cell_metrics_ch2.csv (lys counts filtered)\")\n",
    "    except Exception as e:\n",
    "        print(\"Merge with lysosome counts failed:\", e)\n",
    "\n",
    "# ==========================================\n",
    "# Export full-size overlay (filtered lysosomes only)\n",
    "# ==========================================\n",
    "def _interval_tag(dmin, dmax):\n",
    "    dmin = float(dmin)\n",
    "    if dmax is None:\n",
    "        return f\"diam_{dmin:g}_to_inf_um\"\n",
    "    return f\"diam_{dmin:g}_to_{float(dmax):g}_um\"\n",
    "\n",
    "INTERVAL_TAG = _interval_tag(DIAMETER_MIN_UM, DIAMETER_MAX_UM)\n",
    "\n",
    "if EXPORT_FULLSIZE_OVERLAY:\n",
    "    export_fullsize_overlay_stack(\n",
    "        img_ch1=img_ch1,\n",
    "        img_ch2_raw=img_ch2,\n",
    "        cell_seg_viz=cell_seg_viz,\n",
    "        df=df,  # filtered\n",
    "        vx_um=vx_um, vy_um=vy_um, vz_um=vz_um,\n",
    "        output_dir=output_dir,\n",
    "        alpha_labels=0.45,\n",
    "        draw_only_inside=True,\n",
    "        fps=FPS,\n",
    "        basename=f\"FULLSIZE_overlay_ID_Lysosomes_MAGENTA_{INTERVAL_TAG}\"\n",
    "    )\n",
    "\n",
    "# ==========================================\n",
    "# Videos (MAGENTA lysosomes) (filtered)\n",
    "# ==========================================\n",
    "if GENERATE_VIDEOS:\n",
    "    img_norm_2 = (ch2 * 255).astype(np.uint8)\n",
    "    frames_fused = []\n",
    "    Z = img_norm_2.shape[0]\n",
    "    px_um_xy = float(np.sqrt(vx_um * vy_um))\n",
    "\n",
    "    for z in range(Z):\n",
    "        base = cv2.cvtColor(img_norm_2[z], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        mask_u8 = (cell_mask_viz[z].astype(np.uint8) * 255)\n",
    "        overlay = base.copy()\n",
    "        overlay[..., 1] = np.maximum(overlay[..., 1], mask_u8)\n",
    "        overlay = cv2.addWeighted(base, 1.0, overlay, 0.35, 0.0)\n",
    "\n",
    "        drew_any = False\n",
    "\n",
    "        if isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "            dfv = df[\n",
    "                np.isfinite(df[\"z_um\"]) &\n",
    "                np.isfinite(df[\"y_um\"]) &\n",
    "                np.isfinite(df[\"x_um\"]) &\n",
    "                np.isfinite(df[\"radius_um\"])\n",
    "            ]\n",
    "            if not dfv.empty:\n",
    "                zc = (dfv[\"z_um\"].to_numpy() / vz_um).astype(float)\n",
    "                yc = (dfv[\"y_um\"].to_numpy() / vy_um).astype(float)\n",
    "                xc = (dfv[\"x_um\"].to_numpy() / vx_um).astype(float)\n",
    "                r_um = dfv[\"radius_um\"].to_numpy().astype(float)\n",
    "\n",
    "                dz_um = np.abs(zc - z) * vz_um\n",
    "                hits = dz_um <= r_um\n",
    "\n",
    "                if np.any(hits):\n",
    "                    r_proj_um = np.sqrt(np.clip(r_um[hits]**2 - dz_um[hits]**2, 0.0, None))\n",
    "                    r_proj_px = r_proj_um / max(px_um_xy, 1e-12)\n",
    "\n",
    "                    ys = np.rint(yc[hits]).astype(int)\n",
    "                    xs = np.rint(xc[hits]).astype(int)\n",
    "\n",
    "                    H, W = cell_mask_viz.shape[1], cell_mask_viz.shape[2]\n",
    "                    thickness = 2\n",
    "\n",
    "                    for y, x, rpv in zip(ys, xs, r_proj_px):\n",
    "                        rr = int(max(3, round(rpv)))\n",
    "                        if 0 <= y < H and 0 <= x < W and rr > 0:\n",
    "                            cv2.circle(overlay, (x, y), rr, LYS_EDGE_BGR, thickness + 2, lineType=cv2.LINE_AA)\n",
    "                            cv2.circle(overlay, (x, y), rr, LYS_MAGENTA_BGR, thickness, lineType=cv2.LINE_AA)\n",
    "                            cv2.circle(overlay, (x, y), 1,  LYS_MAGENTA_BGR, -1, lineType=cv2.LINE_AA)\n",
    "                    drew_any = True\n",
    "\n",
    "        # IMPORTANT: do NOT fallback to drawing raw blobs if filtering removed all lysosomes\n",
    "        if (not drew_any) and ALLOW_BLOB_FALLBACK and (blobs is not None) and (len(blobs) > 0):\n",
    "            z_blobs = blobs[np.abs(blobs[:, 0] - z) < 0.5]\n",
    "            H, W = cell_mask_viz.shape[1], cell_mask_viz.shape[2]\n",
    "            thickness = 2\n",
    "            for b in z_blobs:\n",
    "                y, x = int(round(b[1])), int(round(b[2]))\n",
    "                r = int(max(3, round(b[3])))\n",
    "                if 0 <= y < H and 0 <= x < W and r > 0:\n",
    "                    cv2.circle(overlay, (x, y), r, LYS_EDGE_BGR, thickness + 2, lineType=cv2.LINE_AA)\n",
    "                    cv2.circle(overlay, (x, y), r, LYS_MAGENTA_BGR, thickness, lineType=cv2.LINE_AA)\n",
    "                    cv2.circle(overlay, (x, y), 1, LYS_MAGENTA_BGR, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(overlay, f\"FUSED (mask + MAGENTA lysosomes) [{INTERVAL_TAG}]\", (10, 22),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        frames_fused.append(overlay)\n",
    "\n",
    "    try:\n",
    "        imageio.mimsave(f\"ch2_fused_cell_magenta_{INTERVAL_TAG}.mp4\", frames_fused, fps=int(FPS), format=\"FFMPEG\")\n",
    "        print(f\"Saved: ch2_fused_cell_magenta_{INTERVAL_TAG}.mp4\")\n",
    "    except TypeError:\n",
    "        imageio.mimsave(f\"ch2_fused_cell_magenta_{INTERVAL_TAG}.gif\", frames_fused, fps=int(FPS))\n",
    "        print(f\"Saved: ch2_fused_cell_magenta_{INTERVAL_TAG}.gif\")\n",
    "\n",
    "    # RAW+FUSED side-by-side\n",
    "    ch1_u8 = _norm_u8_stack(img_ch1.astype(np.float32))\n",
    "    ch2_u8 = _norm_u8_stack(ch2.astype(np.float32) * 255.0 / max(1.0, ch2.max()))\n",
    "\n",
    "    frames_raw = []\n",
    "    frames_fused_all = []\n",
    "    frames_side_by_side = []\n",
    "\n",
    "    Z = ch2_u8.shape[0]\n",
    "    px_um_xy = float(np.sqrt(vx_um * vy_um))\n",
    "\n",
    "    for z in range(Z):\n",
    "        b = ch1_u8[z]\n",
    "        g = ch2_u8[z]\n",
    "        r = ch1_u8[z]\n",
    "        base = np.dstack([b, g, r])\n",
    "\n",
    "        mask_u8 = (cell_mask_viz[z].astype(np.uint8) * 255)\n",
    "        overlay = base.copy()\n",
    "        overlay[..., 1] = np.maximum(overlay[..., 1], mask_u8)\n",
    "        overlay = cv2.addWeighted(base, 1.0, overlay, 0.35, 0.0)\n",
    "\n",
    "        drew_any = False\n",
    "\n",
    "        if isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "            dfv = df[\n",
    "                np.isfinite(df[\"z_um\"]) &\n",
    "                np.isfinite(df[\"y_um\"]) &\n",
    "                np.isfinite(df[\"x_um\"]) &\n",
    "                np.isfinite(df[\"radius_um\"])\n",
    "            ]\n",
    "            if not dfv.empty:\n",
    "                zc = (dfv[\"z_um\"].to_numpy() / vz_um).astype(float)\n",
    "                yc = (dfv[\"y_um\"].to_numpy() / vy_um).astype(float)\n",
    "                xc = (dfv[\"x_um\"].to_numpy() / vx_um).astype(float)\n",
    "                r_um = dfv[\"radius_um\"].to_numpy().astype(float)\n",
    "\n",
    "                dz_um = np.abs(zc - z) * vz_um\n",
    "                hits = dz_um <= r_um\n",
    "\n",
    "                if np.any(hits):\n",
    "                    r_proj_um = np.sqrt(np.clip(r_um[hits]**2 - dz_um[hits]**2, 0.0, None))\n",
    "                    r_proj_px = r_proj_um / max(px_um_xy, 1e-12)\n",
    "\n",
    "                    ys = np.rint(yc[hits]).astype(int)\n",
    "                    xs = np.rint(xc[hits]).astype(int)\n",
    "\n",
    "                    H, W = cell_mask_viz.shape[1], cell_mask_viz.shape[2]\n",
    "                    thickness = 2\n",
    "\n",
    "                    for y, x, rpv in zip(ys, xs, r_proj_px):\n",
    "                        rr = int(max(3, round(rpv)))\n",
    "                        if 0 <= y < H and 0 <= x < W and rr > 0:\n",
    "                            cv2.circle(overlay, (x, y), rr, LYS_EDGE_BGR, thickness + 2, lineType=cv2.LINE_AA)\n",
    "                            cv2.circle(overlay, (x, y), rr, LYS_MAGENTA_BGR, thickness, lineType=cv2.LINE_AA)\n",
    "                            cv2.circle(overlay, (x, y), 1,  LYS_MAGENTA_BGR, -1, lineType=cv2.LINE_AA)\n",
    "                    drew_any = True\n",
    "\n",
    "        if (not drew_any) and ALLOW_BLOB_FALLBACK and (blobs is not None) and (len(blobs) > 0):\n",
    "            z_blobs = blobs[np.abs(blobs[:, 0] - z) < 0.5]\n",
    "            H, W = cell_mask_viz.shape[1], cell_mask_viz.shape[2]\n",
    "            thickness = 2\n",
    "            for b_ in z_blobs:\n",
    "                y, x = int(round(b_[1])), int(round(b_[2]))\n",
    "                rpx = int(max(3, round(b_[3])))\n",
    "                if 0 <= y < H and 0 <= x < W and rpx > 0:\n",
    "                    cv2.circle(overlay, (x, y), rpx, LYS_EDGE_BGR, thickness + 2, lineType=cv2.LINE_AA)\n",
    "                    cv2.circle(overlay, (x, y), rpx, LYS_MAGENTA_BGR, thickness, lineType=cv2.LINE_AA)\n",
    "                    cv2.circle(overlay, (x, y), 1, LYS_MAGENTA_BGR, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(base, \"RAW (Ch1+Ch2)\", (10, 22),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(overlay, f\"FUSED (mask + MAGENTA lysosomes) [{INTERVAL_TAG}]\", (10, 22),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        frames_raw.append(base)\n",
    "        frames_fused_all.append(overlay)\n",
    "        frames_side_by_side.append(cv2.hconcat([base, overlay]))\n",
    "\n",
    "    def _save_video_sync(basename, frames):\n",
    "        try:\n",
    "            with imageio.get_writer(\n",
    "                f\"{basename}.mp4\",\n",
    "                fps=int(FPS),\n",
    "                format=\"FFMPEG\",\n",
    "                codec=\"libx264\",\n",
    "                macro_block_size=None\n",
    "            ) as w:\n",
    "                for fr in frames:\n",
    "                    w.append_data(fr)\n",
    "            print(f\"Saved: {basename}.mp4 @ {int(FPS)} fps\")\n",
    "        except Exception:\n",
    "            imageio.mimsave(f\"{basename}.gif\", frames, duration=1.0 / max(int(FPS), 1))\n",
    "            print(f\"Saved: {basename}.gif @ {int(FPS)} fps equivalent\")\n",
    "\n",
    "    _save_video_sync(f\"ch2_raw_{INTERVAL_TAG}\", frames_raw)\n",
    "    _save_video_sync(f\"ch2_fused_all_viz_magenta_{INTERVAL_TAG}\", frames_fused_all)\n",
    "    _save_video_sync(f\"ch2_raw_and_fused_all_viz_magenta_{INTERVAL_TAG}\", frames_side_by_side)\n",
    "\n",
    "# ==========================================\n",
    "# Napari visualization (filtered)\n",
    "# ==========================================\n",
    "\"\"\"\n",
    "if LAUNCH_VIEWER:\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.dims.ndisplay = 3\n",
    "\n",
    "    viewer.add_image(img_ch2, name=\"Ch2 raw\")\n",
    "    viewer.add_image(img_ch1, name=\"Ch1 raw\")\n",
    "\n",
    "    mask_layer = viewer.add_labels(\n",
    "        cell_mask_viz.astype(np.uint8),\n",
    "        name=\"Neurite mask (viz)\" if NEURITE_MODE else \"Cell mask (viz)\",\n",
    "        opacity=0.35\n",
    "    )\n",
    "    mask_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    id_layer = viewer.add_labels(\n",
    "        cell_seg_viz.astype(np.uint16),\n",
    "        name=\"ID (viz)\",\n",
    "        opacity=0.25\n",
    "    )\n",
    "    id_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    # Points layer: filtered lysosomes inside neurites\n",
    "    if len(df) > 0 and \"location_ch2\" in df:\n",
    "        in_mask = (df[\"location_ch2\"].to_numpy() == \"cell\")\n",
    "        if np.any(in_mask):\n",
    "            pts_zyx = np.stack([\n",
    "                (df.loc[in_mask, \"z_um\"].to_numpy() / vz_um),\n",
    "                (df.loc[in_mask, \"y_um\"].to_numpy() / vy_um),\n",
    "                (df.loc[in_mask, \"x_um\"].to_numpy() / vx_um),\n",
    "            ], axis=1)\n",
    "\n",
    "            radii_vox = df.loc[in_mask, \"radius_um\"].to_numpy() / (np.sqrt(vx_um * vy_um) + 1e-12)\n",
    "            sizes = np.clip(radii_vox * 2, 2, None).astype(np.float32)\n",
    "\n",
    "            pts = viewer.add_points(pts_zyx, size=sizes, name=f\"Lysosomes (filtered {INTERVAL_TAG})\")\n",
    "            pts.face_color = [1.0, 0.0, 1.0, 1.0]\n",
    "            pts.edge_color = \"black\"\n",
    "            pts.edge_width = 0.3\n",
    "\n",
    "            cell_ids = df.loc[in_mask, \"cell_id_ch2_viz\"].to_numpy().astype(int) if \"cell_id_ch2_viz\" in df.columns else np.zeros(int(np.sum(in_mask)), dtype=int)\n",
    "            lys_ids  = df.loc[in_mask, \"lys_id_in_cell\"].to_numpy().astype(int) if \"lys_id_in_cell\" in df.columns else np.zeros(int(np.sum(in_mask)), dtype=int)\n",
    "            diams    = df.loc[in_mask, \"diameter_um\"].to_numpy().astype(float)\n",
    "\n",
    "            info = np.array(\n",
    "                [f\"ID:{c}  Ly:{l}  Diam:{d:.3f}µm\" for c, l, d in zip(cell_ids, lys_ids, diams)],\n",
    "                dtype=object\n",
    "            )\n",
    "            pts.properties = {\"info\": info}\n",
    "\n",
    "    keep = {\"ID (viz)\", \"Neurite mask (viz)\", \"Cell mask (viz)\", \"Ch1 raw\", \"Ch2 raw\"}\n",
    "    for lyr in list(viewer.layers):\n",
    "        if lyr.name not in keep and not lyr.name.startswith(\"Lysosomes (filtered\"):\n",
    "            viewer.layers.remove(lyr)\n",
    "\n",
    "    try:\n",
    "        viewer.camera.zoom = 1.2\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    napari.run()\n",
    "\"\"\"\n",
    "# ==========================================\n",
    "# Napari visualization + OPTIONAL editing of lysosome table (SERIAL IDs + SERIAL lys index)\n",
    "# ==========================================\n",
    "if LAUNCH_VIEWER:\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.dims.ndisplay = 3\n",
    "\n",
    "    viewer.add_image(img_ch2, name=\"Ch2 raw\")\n",
    "    viewer.add_image(img_ch1, name=\"Ch1 raw\")\n",
    "\n",
    "    mask_layer = viewer.add_labels(\n",
    "        cell_mask_viz.astype(np.uint8),\n",
    "        name=\"Neurite mask\" if NEURITE_MODE else \"Cell mask\",\n",
    "        opacity=0.35\n",
    "    )\n",
    "    mask_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    id_layer = viewer.add_labels(\n",
    "        cell_seg_viz.astype(np.uint16),\n",
    "        name=\"ID (serial)\",\n",
    "        opacity=0.25\n",
    "    )\n",
    "    id_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    # ---- Build an editable Points layer representing rows of df ----\n",
    "    pts_layer = None\n",
    "\n",
    "    # Map: serial_id -> original_id (so you can still export original IDs too)\n",
    "    serial_to_original_id = None\n",
    "    if isinstance(cell_id_map_viz, dict) and len(cell_id_map_viz) > 0:\n",
    "        # cell_id_map_viz maps: original_id -> serial_id\n",
    "        serial_to_original_id = {serial_id: original_id for (original_id, serial_id) in cell_id_map_viz.items()}\n",
    "\n",
    "    if EDIT_LYSOSOME_TABLE_IN_NAPARI and isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "        # Use ALL filtered lysosomes (both \"cell\" and \"outside\") so you can correct the CSV.\n",
    "        df_edit = df.copy()\n",
    "\n",
    "        pts_zyx = np.stack([\n",
    "            (df_edit[\"z_um\"].to_numpy() / vz_um),\n",
    "            (df_edit[\"y_um\"].to_numpy() / vy_um),\n",
    "            (df_edit[\"x_um\"].to_numpy() / vx_um),\n",
    "        ], axis=1).astype(np.float32)\n",
    "\n",
    "        # Point size from radius (safe fallback)\n",
    "        if \"radius_um\" in df_edit.columns:\n",
    "            radii_vox = df_edit[\"radius_um\"].to_numpy(dtype=float) / (np.sqrt(vx_um * vy_um) + 1e-12)\n",
    "            sizes = np.clip(radii_vox * 2, 2, None).astype(np.float32)\n",
    "        else:\n",
    "            sizes = np.full((pts_zyx.shape[0],), 6, dtype=np.float32)\n",
    "\n",
    "        # ---- Ensure required columns exist (using \"serial\" naming) ----\n",
    "        if \"location_ch2\" not in df_edit.columns:\n",
    "            df_edit[\"location_ch2\"] = \"outside\"\n",
    "\n",
    "        # If user already has serial columns, use them; otherwise fall back to old names; otherwise initialize\n",
    "        if \"cell_id_serial\" in df_edit.columns:\n",
    "            df_edit[\"cell_id_serial\"] = df_edit[\"cell_id_serial\"].fillna(0).astype(int)\n",
    "        elif \"cell_id_ch2_viz\" in df_edit.columns:\n",
    "            df_edit[\"cell_id_serial\"] = df_edit[\"cell_id_ch2_viz\"].fillna(0).astype(int)\n",
    "        else:\n",
    "            # try to build serial from original id if possible\n",
    "            if \"cell_id_ch2\" in df_edit.columns and isinstance(cell_id_map_viz, dict):\n",
    "                df_edit[\"cell_id_serial\"] = df_edit[\"cell_id_ch2\"].map(cell_id_map_viz).fillna(0).astype(int)\n",
    "            else:\n",
    "                df_edit[\"cell_id_serial\"] = 0\n",
    "\n",
    "        if \"cell_id_ch2\" not in df_edit.columns:\n",
    "            df_edit[\"cell_id_ch2\"] = 0\n",
    "        df_edit[\"cell_id_ch2\"] = df_edit[\"cell_id_ch2\"].fillna(0).astype(int)\n",
    "\n",
    "        # ---- Compute lys_id_serial (reset per cell_id_serial) ----\n",
    "        def _recompute_lys_id_serial(cell_id_serial_arr, location_arr):\n",
    "            n = int(len(cell_id_serial_arr))\n",
    "            out = np.zeros(n, dtype=int)\n",
    "\n",
    "            # Only \"cell\" with serial > 0 get numbering\n",
    "            mask = (location_arr.astype(str) == \"cell\") & (cell_id_serial_arr.astype(int) > 0)\n",
    "            if not np.any(mask):\n",
    "                return out\n",
    "\n",
    "            tmp = pd.DataFrame({\n",
    "                \"idx\": np.arange(n, dtype=int),\n",
    "                \"cell_id_serial\": cell_id_serial_arr.astype(int),\n",
    "                \"z_um\": df_edit[\"z_um\"].to_numpy(dtype=float),\n",
    "                \"y_um\": df_edit[\"y_um\"].to_numpy(dtype=float),\n",
    "                \"x_um\": df_edit[\"x_um\"].to_numpy(dtype=float),\n",
    "            })\n",
    "            tmp = tmp.loc[mask].sort_values([\"cell_id_serial\", \"z_um\", \"y_um\", \"x_um\"], kind=\"mergesort\")\n",
    "            serial = (tmp.groupby(\"cell_id_serial\").cumcount().to_numpy() + 1).astype(int)\n",
    "            out[tmp[\"idx\"].to_numpy(dtype=int)] = serial\n",
    "            return out\n",
    "\n",
    "        loc0 = df_edit[\"location_ch2\"].astype(str).to_numpy()\n",
    "        cell_serial0 = df_edit[\"cell_id_serial\"].astype(int).to_numpy()\n",
    "        lys_serial0 = _recompute_lys_id_serial(cell_serial0, loc0)\n",
    "        df_edit[\"lys_id_serial\"] = lys_serial0\n",
    "\n",
    "        # Label string shown in napari: ONLY cell_id_serial + lys_id_serial\n",
    "        label0 = np.array([f\"{c}:{l}\" for (c, l) in zip(cell_serial0, lys_serial0)], dtype=object)\n",
    "\n",
    "        props = {\n",
    "            \"location_ch2\": loc0,\n",
    "            #\"cell_id_ch2\": df_edit[\"cell_id_ch2\"].astype(int).to_numpy(),      # original ID (kept for export)\n",
    "            \"cell_id_serial\": cell_serial0,                                   # what you see on screen\n",
    "            \"lys_id_serial\": lys_serial0,                                     # reset per cell_id_serial\n",
    "            #\"label\": label0,                                                  # what gets displayed\n",
    "        }\n",
    "\n",
    "        pts_layer = viewer.add_points(\n",
    "            pts_zyx,\n",
    "            size=sizes,\n",
    "            name=\"Lysosomes (EDIT TABLE)\",\n",
    "            properties=props,\n",
    "        )\n",
    "        pts_layer.face_color = [1.0, 0.0, 1.0, 1.0]\n",
    "        pts_layer.edge_color = \"black\"\n",
    "        pts_layer.edge_width = 0.3\n",
    "        pts_layer.mode = \"select\"  # avoid accidental adding/removing\n",
    "\n",
    "        #pts_layer.text = {\"string\": \"{label}\", \"size\": 10, \"color\": \"white\"}\n",
    "\n",
    "        def _refresh_labels_and_serials():\n",
    "            \"\"\"Recompute lys_id_serial and refresh displayed labels after any edits.\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            p = dict(pts_layer.properties)\n",
    "\n",
    "            loc = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            cell_serial = np.array(p[\"cell_id_serial\"]).astype(int)\n",
    "\n",
    "            lys_serial = _recompute_lys_id_serial(cell_serial, loc)\n",
    "            p[\"lys_id_serial\"] = lys_serial\n",
    "\n",
    "            p[\"label\"] = np.array([f\"{c}:{l}\" for (c, l) in zip(cell_serial, lys_serial)], dtype=object)\n",
    "            pts_layer.properties = p\n",
    "\n",
    "        def _apply_props_update(indices, new_loc=None, new_cell_serial=None):\n",
    "            \"\"\"Update selected points then recompute lys serials + labels.\"\"\"\n",
    "            if pts_layer is None or not indices:\n",
    "                return\n",
    "\n",
    "            p = dict(pts_layer.properties)\n",
    "            loc = np.array(p[\"location_ch2\"]).astype(object)\n",
    "            cell_serial = np.array(p[\"cell_id_serial\"]).astype(int)\n",
    "            cell_orig = np.array(p[\"cell_id_ch2\"]).astype(int)\n",
    "\n",
    "            for i in indices:\n",
    "                if new_loc is not None:\n",
    "                    loc[i] = str(new_loc)\n",
    "\n",
    "                if new_cell_serial is not None:\n",
    "                    sid = int(new_cell_serial)\n",
    "                    cell_serial[i] = sid\n",
    "\n",
    "                    # keep original id consistent (if mapping exists)\n",
    "                    if serial_to_original_id is not None:\n",
    "                        cell_orig[i] = int(serial_to_original_id.get(sid, 0))\n",
    "                    else:\n",
    "                        cell_orig[i] = int(sid)\n",
    "\n",
    "                if new_loc == \"outside\":\n",
    "                    cell_serial[i] = 0\n",
    "                    cell_orig[i] = 0\n",
    "\n",
    "            p[\"location_ch2\"] = loc.astype(str)\n",
    "            p[\"cell_id_serial\"] = cell_serial.astype(int)\n",
    "            p[\"cell_id_ch2\"] = cell_orig.astype(int)\n",
    "            pts_layer.properties = p\n",
    "\n",
    "            _refresh_labels_and_serials()\n",
    "\n",
    "        @viewer.bind_key(\"A\")\n",
    "        def assign_selected_to_id_under_cursor(event=None):\n",
    "            \"\"\"Assign selected points to the SERIAL ID under the mouse cursor (from ID (serial)).\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            sel = sorted(list(pts_layer.selected_data))\n",
    "            if not sel:\n",
    "                print(\"[Napari edit] No points selected.\")\n",
    "                return\n",
    "\n",
    "            zf, yf, xf = viewer.cursor.position\n",
    "            zz, yy, xx = int(round(zf)), int(round(yf)), int(round(xf))\n",
    "\n",
    "            if not (0 <= zz < cell_seg_viz.shape[0] and 0 <= yy < cell_seg_viz.shape[1] and 0 <= xx < cell_seg_viz.shape[2]):\n",
    "                print(\"[Napari edit] Cursor is out of bounds.\")\n",
    "                return\n",
    "\n",
    "            serial_id = int(cell_seg_viz[zz, yy, xx])\n",
    "            if serial_id <= 0:\n",
    "                print(\"[Napari edit] Cursor is not over a labeled SERIAL ID.\")\n",
    "                return\n",
    "\n",
    "            _apply_props_update(sel, new_loc=\"cell\", new_cell_serial=serial_id)\n",
    "            print(f\"[Napari edit] Assigned {len(sel)} lysosomes -> serial ID {serial_id}\")\n",
    "\n",
    "        @viewer.bind_key(\"X\")\n",
    "        def mark_selected_outside(event=None):\n",
    "            \"\"\"Mark selected points as outside (location='outside', ids=0).\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            sel = sorted(list(pts_layer.selected_data))\n",
    "            if not sel:\n",
    "                print(\"[Napari edit] No points selected.\")\n",
    "                return\n",
    "            _apply_props_update(sel, new_loc=\"outside\", new_cell_serial=0)\n",
    "            print(f\"[Napari edit] Marked {len(sel)} lysosomes as outside\")\n",
    "        \"\"\"\n",
    "        def _export_edited_csv(path):\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)          # original ID\n",
    "            df_out[\"cell_id_serial\"] = np.array(p[\"cell_id_serial\"]).astype(int)    # serial ID shown on screen\n",
    "            df_out[\"lys_id_serial\"] = np.array(p[\"lys_id_serial\"]).astype(int)      # per-cell serial lys index\n",
    "\n",
    "            df_out.to_csv(path, index=False)\n",
    "            print(f\"[Napari edit] Saved edited lysosome table: {path}\")\n",
    "        \"\"\"\n",
    "        def _export_edited_csv(path):\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "\n",
    "            # update edited fields\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)          # original ID\n",
    "            df_out[\"cell_id_serial\"] = np.array(p[\"cell_id_serial\"]).astype(int)    # serial ID shown on screen\n",
    "            df_out[\"lys_id_serial\"] = np.array(p[\"lys_id_serial\"]).astype(int)      # per-cell serial lys index\n",
    "\n",
    "            # NEW: pull diameter_um + peak_gray from lysosome_blobs_regions_ALL.csv by id\n",
    "            df_out = attach_all_blob_fields(df_out)\n",
    "\n",
    "            df_out.to_csv(path, index=False)\n",
    "            print(f\"[Napari edit] Saved edited lysosome table: {path}\")\n",
    "        \n",
    "        @viewer.bind_key(\"S\")\n",
    "        def save_now(event=None):\n",
    "            _export_edited_csv(LYSOSOME_EDITED_CSV)\n",
    "\n",
    "    try:\n",
    "        viewer.camera.zoom = 1.2\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "    if EDIT_LYSOSOME_TABLE_IN_NAPARI and pts_layer is not None:\n",
    "        try:\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)\n",
    "            df_out[\"cell_id_serial\"] = np.array(p[\"cell_id_serial\"]).astype(int)\n",
    "            df_out[\"lys_id_serial\"] = np.array(p[\"lys_id_serial\"]).astype(int)\n",
    "\n",
    "            # NEW: pull diameter_um + peak_gray from lysosome_blobs_regions_ALL.csv by id\n",
    "            df_out = attach_all_blob_fields(df_out)\n",
    "\n",
    "            df_out.to_csv(LYSOSOME_EDITED_CSV, index=False)\n",
    "            print(f\"[Napari edit] Auto-saved edited lysosome table: {LYSOSOME_EDITED_CSV}\")\n",
    "        except Exception as e:\n",
    "            print(\"[Napari edit] Auto-save failed:\", e)\n",
    "\"\"\"\n",
    "    #Auto-save on close\n",
    "    if EDIT_LYSOSOME_TABLE_IN_NAPARI and pts_layer is not None:\n",
    "        try:\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)\n",
    "            df_out[\"cell_id_serial\"] = np.array(p[\"cell_id_serial\"]).astype(int)\n",
    "            df_out[\"lys_id_serial\"] = np.array(p[\"lys_id_serial\"]).astype(int)\n",
    "\n",
    "            df_out.to_csv(LYSOSOME_EDITED_CSV, index=False)\n",
    "            print(f\"[Napari edit] Auto-saved edited lysosome table: {LYSOSOME_EDITED_CSV}\")\n",
    "        except Exception as e:\n",
    "            print(\"[Napari edit] Auto-save failed:\", e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc6b62-e58a-4915-8636-f1457677d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####version anterior de visualizacion######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477cfc24-c26a-4155-82c1-610dd47e0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LAUNCH_VIEWER:\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.dims.ndisplay = 3\n",
    "\n",
    "    viewer.add_image(img_ch2, name=\"Ch2 raw\")\n",
    "    viewer.add_image(img_ch1, name=\"Ch1 raw\")\n",
    "\n",
    "    mask_layer = viewer.add_labels(\n",
    "        cell_mask_viz.astype(np.uint8),\n",
    "        name=\"Neurite mask (viz)\" if NEURITE_MODE else \"Cell mask (viz)\",\n",
    "        opacity=0.35\n",
    "    )\n",
    "    mask_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    id_layer = viewer.add_labels(\n",
    "        cell_seg_viz.astype(np.uint16),\n",
    "        name=\"ID (viz)\",\n",
    "        opacity=0.25\n",
    "    )\n",
    "    id_layer.blending = \"translucent_no_depth\"\n",
    "\n",
    "    # ---- Build an editable Points layer representing *rows* of df ----\n",
    "    pts_layer = None\n",
    "    inv_viz_map = None  # maps viz_id -> original cell_seg id\n",
    "    if isinstance(cell_id_map_viz, dict) and len(cell_id_map_viz) > 0:\n",
    "        inv_viz_map = {new_id: old_id for (old_id, new_id) in cell_id_map_viz.items()}\n",
    "\n",
    "    if EDIT_LYSOSOME_TABLE_IN_NAPARI and isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "        # Use ALL filtered lysosomes (both \"cell\" and \"outside\") so you can correct the CSV.\n",
    "        df_edit = df.copy()\n",
    "\n",
    "        pts_zyx = np.stack([\n",
    "            (df_edit[\"z_um\"].to_numpy() / vz_um),\n",
    "            (df_edit[\"y_um\"].to_numpy() / vy_um),\n",
    "            (df_edit[\"x_um\"].to_numpy() / vx_um),\n",
    "        ], axis=1).astype(np.float32)\n",
    "\n",
    "        # Point size from radius (safe fallback)\n",
    "        if \"radius_um\" in df_edit.columns:\n",
    "            radii_vox = df_edit[\"radius_um\"].to_numpy(dtype=float) / (np.sqrt(vx_um * vy_um) + 1e-12)\n",
    "            sizes = np.clip(radii_vox * 2, 2, None).astype(np.float32)\n",
    "        else:\n",
    "            sizes = np.full((pts_zyx.shape[0],), 6, dtype=np.float32)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if \"location_ch2\" not in df_edit.columns:\n",
    "            df_edit[\"location_ch2\"] = \"outside\"\n",
    "        if \"cell_id_ch2\" not in df_edit.columns:\n",
    "            df_edit[\"cell_id_ch2\"] = 0\n",
    "        if \"cell_id_ch2_viz\" not in df_edit.columns:\n",
    "            # derive viz id if possible\n",
    "            if isinstance(cell_id_map_viz, dict):\n",
    "                df_edit[\"cell_id_ch2_viz\"] = df_edit[\"cell_id_ch2\"].map(cell_id_map_viz).fillna(0).astype(int)\n",
    "            else:\n",
    "                df_edit[\"cell_id_ch2_viz\"] = 0\n",
    "\n",
    "        props = {\n",
    "            \"location_ch2\": df_edit[\"location_ch2\"].astype(str).to_numpy(),\n",
    "            \"cell_id_ch2\": df_edit[\"cell_id_ch2\"].astype(int).to_numpy(),\n",
    "            \"cell_id_ch2_viz\": df_edit[\"cell_id_ch2_viz\"].astype(int).to_numpy(),\n",
    "        }\n",
    "\n",
    "        pts_layer = viewer.add_points(\n",
    "            pts_zyx,\n",
    "            size=sizes,\n",
    "            name=\"Lysosomes (EDIT TABLE)\",\n",
    "            properties=props,\n",
    "        )\n",
    "        pts_layer.face_color = [1.0, 0.0, 1.0, 1.0]\n",
    "        pts_layer.edge_color = \"black\"\n",
    "        pts_layer.edge_width = 0.3\n",
    "        pts_layer.mode = \"select\"  # important: avoid accidental adding/removing\n",
    "\n",
    "        # show ID/viz/location as an on-screen label per point\n",
    "        txt = np.array(\n",
    "            [f\"viz:{v}  id:{c}  {loc}\"\n",
    "             for (v, c, loc) in zip(props[\"cell_id_ch2_viz\"], props[\"cell_id_ch2\"], props[\"location_ch2\"])],\n",
    "            dtype=object\n",
    "        )\n",
    "        pts_layer.properties = dict(pts_layer.properties, info=txt)\n",
    "        pts_layer.text = {\"string\": \"{info}\", \"size\": 10, \"color\": \"white\"}\n",
    "\n",
    "        def _apply_props_update(indices, new_loc=None, new_viz_id=None):\n",
    "            \"\"\"Update pts_layer.properties arrays in-place (safe for napari).\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            if not indices:\n",
    "                return\n",
    "\n",
    "            p = dict(pts_layer.properties)\n",
    "            loc = p.get(\"location_ch2\")\n",
    "            cid = p.get(\"cell_id_ch2\")\n",
    "            viz = p.get(\"cell_id_ch2_viz\")\n",
    "\n",
    "            for i in indices:\n",
    "                if new_loc is not None:\n",
    "                    loc[i] = str(new_loc)\n",
    "\n",
    "                if new_viz_id is not None:\n",
    "                    viz_id = int(new_viz_id)\n",
    "                    viz[i] = viz_id\n",
    "\n",
    "                    # keep original id consistent with viz id if we can\n",
    "                    if inv_viz_map is not None:\n",
    "                        cid[i] = int(inv_viz_map.get(viz_id, 0))\n",
    "                    else:\n",
    "                        # fallback: if no mapping, store viz id in both (better than losing it)\n",
    "                        cid[i] = int(viz_id)\n",
    "\n",
    "                # if marking outside, force ids to 0\n",
    "                if new_loc == \"outside\":\n",
    "                    viz[i] = 0\n",
    "                    cid[i] = 0\n",
    "\n",
    "            # refresh the on-screen info text\n",
    "            info = p.get(\"info\")\n",
    "            for i in indices:\n",
    "                info[i] = f\"viz:{int(viz[i])}  id:{int(cid[i])}  {str(loc[i])}\"\n",
    "\n",
    "            p[\"location_ch2\"] = loc\n",
    "            p[\"cell_id_ch2\"] = cid\n",
    "            p[\"cell_id_ch2_viz\"] = viz\n",
    "            p[\"info\"] = info\n",
    "            pts_layer.properties = p\n",
    "\n",
    "        @viewer.bind_key(\"A\")\n",
    "        def assign_selected_to_id_under_cursor(event=None):\n",
    "            \"\"\"Assign selected points to the ID under the mouse cursor (from ID (viz)).\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            sel = sorted(list(pts_layer.selected_data))\n",
    "            if not sel:\n",
    "                print(\"[Napari edit] No points selected.\")\n",
    "                return\n",
    "\n",
    "            zf, yf, xf = viewer.cursor.position  # napari gives world coords; here it matches zyx index space\n",
    "            zz, yy, xx = int(round(zf)), int(round(yf)), int(round(xf))\n",
    "\n",
    "            if not (0 <= zz < cell_seg_viz.shape[0] and 0 <= yy < cell_seg_viz.shape[1] and 0 <= xx < cell_seg_viz.shape[2]):\n",
    "                print(\"[Napari edit] Cursor is out of bounds.\")\n",
    "                return\n",
    "\n",
    "            viz_id = int(cell_seg_viz[zz, yy, xx])\n",
    "            if viz_id <= 0:\n",
    "                print(\"[Napari edit] Cursor is not over a labeled ID (viz).\")\n",
    "                return\n",
    "\n",
    "            _apply_props_update(sel, new_loc=\"cell\", new_viz_id=viz_id)\n",
    "            print(f\"[Napari edit] Assigned {len(sel)} lysosomes -> viz ID {viz_id}\")\n",
    "\n",
    "        @viewer.bind_key(\"X\")\n",
    "        def mark_selected_outside(event=None):\n",
    "            \"\"\"Mark selected points as outside (location_ch2='outside', ids=0).\"\"\"\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            sel = sorted(list(pts_layer.selected_data))\n",
    "            if not sel:\n",
    "                print(\"[Napari edit] No points selected.\")\n",
    "                return\n",
    "            _apply_props_update(sel, new_loc=\"outside\", new_viz_id=0)\n",
    "            print(f\"[Napari edit] Marked {len(sel)} lysosomes as outside\")\n",
    "\n",
    "        def _export_edited_csv(path):\n",
    "            if pts_layer is None:\n",
    "                return\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)\n",
    "            df_out[\"cell_id_ch2_viz\"] = np.array(p[\"cell_id_ch2_viz\"]).astype(int)\n",
    "            df_out.to_csv(path, index=False)\n",
    "            print(f\"[Napari edit] Saved edited lysosome table: {path}\")\n",
    "\n",
    "        @viewer.bind_key(\"S\")\n",
    "        def save_now(event=None):\n",
    "            _export_edited_csv(LYSOSOME_EDITED_CSV)\n",
    "\n",
    "    # Keep your original filtered-inside points layer too (optional)\n",
    "    if (not EDIT_LYSOSOME_TABLE_IN_NAPARI) and len(df) > 0 and \"location_ch2\" in df:\n",
    "        in_mask = (df[\"location_ch2\"].to_numpy() == \"cell\")\n",
    "        if np.any(in_mask):\n",
    "            pts_zyx = np.stack([\n",
    "                (df.loc[in_mask, \"z_um\"].to_numpy() / vz_um),\n",
    "                (df.loc[in_mask, \"y_um\"].to_numpy() / vy_um),\n",
    "                (df.loc[in_mask, \"x_um\"].to_numpy() / vx_um),\n",
    "            ], axis=1)\n",
    "\n",
    "            radii_vox = df.loc[in_mask, \"radius_um\"].to_numpy() / (np.sqrt(vx_um * vy_um) + 1e-12)\n",
    "            sizes = np.clip(radii_vox * 2, 2, None).astype(np.float32)\n",
    "\n",
    "            pts = viewer.add_points(pts_zyx, size=sizes, name=\"Lysosomes (inside)\")\n",
    "            pts.face_color = [1.0, 0.0, 1.0, 1.0]\n",
    "            pts.edge_color = \"black\"\n",
    "            pts.edge_width = 0.3\n",
    "\n",
    "    try:\n",
    "        viewer.camera.zoom = 1.2\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "    # Auto-save on close (so you never lose edits)\n",
    "    if EDIT_LYSOSOME_TABLE_IN_NAPARI and pts_layer is not None:\n",
    "        try:\n",
    "            p = pts_layer.properties\n",
    "            df_out = df_edit.copy()\n",
    "            df_out[\"location_ch2\"] = np.array(p[\"location_ch2\"]).astype(str)\n",
    "            df_out[\"cell_id_ch2\"] = np.array(p[\"cell_id_ch2\"]).astype(int)\n",
    "            df_out[\"cell_id_ch2_viz\"] = np.array(p[\"cell_id_ch2_viz\"]).astype(int)\n",
    "            df_out.to_csv(LYSOSOME_EDITED_CSV, index=False)\n",
    "            print(f\"[Napari edit] Auto-saved edited lysosome table: {LYSOSOME_EDITED_CSV}\")\n",
    "        except Exception as e:\n",
    "            print(\"[Napari edit] Auto-save failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bafd41-9498-41dc-8cc4-d6749659977a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
