{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38848a90-c647-47a9-94d0-5b365fe21b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Standard Library Imports ─────────────────────────────\n",
    "import os  # Operating system interaction\n",
    "import sys  # Access to system-specific parameters and functions\n",
    "import json  # Reading and writing JSON configuration\n",
    "import zipfile  # Handling ZIP file creation\n",
    "\n",
    "# ─── Third-party Imports ──────────────────────────────────\n",
    "import cv2  # OpenCV for image processing\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation and tables\n",
    "import openpyxl  # Excel file I/O\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import matplotlib  # Matplotlib config\n",
    "matplotlib.use(\"Qt5Agg\")  # Use Qt5Agg backend for GUI support\n",
    "\n",
    "# ─── PyQt5 GUI Components ────────────────────────────────\n",
    "from PyQt5.QtWidgets import (\n",
    "    QApplication, QWidget, QLabel, QLineEdit, QPushButton,\n",
    "    QVBoxLayout, QHBoxLayout, QFileDialog, QMessageBox,\n",
    "    QTextEdit, QInputDialog, QComboBox\n",
    ")\n",
    "\n",
    "# ─── Image I/O ───────────────────────────────────────────\n",
    "import imageio.v2 as imageio  # Image reading/writing (legacy v2 API)\n",
    "\n",
    "# ─── Skimage Modules for Image Processing ────────────────\n",
    "from skimage.measure import label, regionprops  # Region labeling\n",
    "from skimage.filters import threshold_li, threshold_otsu, threshold_isodata, sobel, threshold_local,gabor  # Threshold methods\n",
    "from skimage import data, filters, measure, exposure, morphology, segmentation, feature, io # Generic image ops\n",
    "from skimage.color import rgb2gray, label2rgb  # Convert RGB to grayscale\n",
    "from skimage.morphology import (\n",
    "    opening, remove_small_objects, remove_small_holes, disk, dilation, closing, erosion\n",
    ")  # Morphological ops\n",
    "from skimage import exposure, color  # Image enhancement and color ops\n",
    "from skimage.feature import peak_local_max  # Peak detection\n",
    "from skimage.segmentation import (\n",
    "    morphological_chan_vese, slic, active_contour,\n",
    "    watershed, random_walker\n",
    ")  # Various segmentation algorithms\n",
    "from skimage.io import imread  # Image reading\n",
    "from skimage.transform import resize  # Image resizing\n",
    "from skimage import draw  # Drawing shapes\n",
    "import skimage.exposure\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# ─── SciPy for Advanced Processing ───────────────────────\n",
    "import scipy.ndimage as ndi  # Multidimensional processing\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import distance_transform_edt, label as ndi_label  # Distance transforms and labeling\n",
    "from scipy import ndimage  # General ndimage support\n",
    "from scipy.signal import find_peaks  # Signal peak detection\n",
    "\n",
    "# ─── Machine Learning ─────────────────────────────────────\n",
    "from sklearn.cluster import KMeans  # Clustering (e.g., for region grouping)\n",
    "\n",
    "# ─── Excel Writing ───────────────────────────────────────\n",
    "from xlsxwriter import Workbook  # Advanced Excel writing\n",
    "\n",
    "# ─── Qt Event Processing ─────────────────────────────────\n",
    "QApplication.processEvents()  # Process any pending GUI events\n",
    "\n",
    "# ─── Threading & Event Control ───────────────────────────\n",
    "from threading import Event  # Used to signal stopping of processing\n",
    "\n",
    "# ─── Utilities ────────────────────────────────────────────\n",
    "from collections import defaultdict  # Dictionary that creates default values automatically\n",
    "\n",
    "import gc\n",
    "\n",
    "# ─────────────────────────────────────────────────────────\n",
    "# GUI Application Class for Image Processing\n",
    "class ImageProcessingApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()  # Set up GUI layout\n",
    "\n",
    "        # Initialize folder paths and control flags\n",
    "        self.input_folder = \"\"\n",
    "        self.output_folder = \"\"\n",
    "        self.processing_active = False  # Track if a process is currently running\n",
    "        self.stop_event = Event()  # Event to handle stop signal\n",
    "\n",
    "    def initUI(self):\n",
    "        # Create the GUI layout\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        # Labels for folder selection display\n",
    "        self.input_label = QLabel(\"Input Folder: Not selected\")\n",
    "        self.output_label = QLabel(\"Output Folder: Not selected\")\n",
    "\n",
    "        # Buttons for actions and controls\n",
    "        self.input_button = QPushButton(\"Select Input Folder\")\n",
    "        self.output_button = QPushButton(\"Select Output Folder\")\n",
    "        self.process_button = QPushButton(\"Detector GRAYSCALE\")\n",
    "        self.process_button_2 = QPushButton(\"Detector MAGENTA\")\n",
    "        self.stop_button = QPushButton(\"Stop Processing\")\n",
    "        self.restart_button = QPushButton(\"Restart Processing\")\n",
    "\n",
    "        # Log output window\n",
    "        self.log_output = QTextEdit()\n",
    "        self.log_output.setReadOnly(True)\n",
    "\n",
    "        # Connect button actions to their corresponding methods\n",
    "        self.input_button.clicked.connect(self.select_input_folder)\n",
    "        self.output_button.clicked.connect(self.select_output_folder)\n",
    "        self.process_button.clicked.connect(self.start_processing)\n",
    "        self.process_button_2.clicked.connect(self.start_processing_2)\n",
    "        self.stop_button.clicked.connect(self.stop_processing)\n",
    "        self.restart_button.clicked.connect(self.restart_processing)\n",
    "\n",
    "        # Add widgets to the GUI layout\n",
    "        layout.addWidget(self.input_label)\n",
    "        layout.addWidget(self.input_button)\n",
    "        layout.addWidget(self.output_label)\n",
    "        layout.addWidget(self.output_button)\n",
    "        layout.addWidget(self.process_button)\n",
    "        layout.addWidget(self.process_button_2)\n",
    "        layout.addWidget(self.log_output)\n",
    "        layout.addWidget(self.stop_button)\n",
    "        layout.addWidget(self.restart_button)\n",
    "\n",
    "        # Finalize window settings\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle(\"Batch Image Processing\")\n",
    "        self.resize(500, 400)\n",
    "\n",
    "    def log(self, message):\n",
    "        # Append a log message to the log output display (likely a QTextEdit or QListWidget)\n",
    "        self.log_output.append(message)\n",
    "\n",
    "    def on_custom_um_entered(self):\n",
    "        # Handle user entering a custom µm value in the combo box\n",
    "        text = self.known_um_combo.currentText().strip()\n",
    "    \n",
    "        # If the entered text is not already in the combo box, add it\n",
    "        if text not in [self.known_um_combo.itemText(i) for i in range(self.known_um_combo.count())]:\n",
    "            self.known_um_combo.addItem(text)\n",
    "\n",
    "    def select_input_folder(self):\n",
    "        # Prompt user to select a folder for BF (Brightfield) images\n",
    "        self.input_folder = QFileDialog.getExistingDirectory(self, \"Select Input Folder\")\n",
    "        self.input_label.setText(f\"BF Folder: {self.input_folder}\")\n",
    "\n",
    "    def select_output_folder(self):\n",
    "        # Prompt user to select a folder to save outputs\n",
    "        self.output_folder = QFileDialog.getExistingDirectory(self, \"Select Output Folder\")\n",
    "        self.output_label.setText(f\"Output Folder: {self.output_folder}\")\n",
    "\n",
    "    def stop_processing(self):\n",
    "        # Set the stop event flag to signal that processing should stop\n",
    "        self.stop_event.set()\n",
    "        self.log(\"Stopping process...\")\n",
    "\n",
    "    def restart_processing(self):\n",
    "        # Stop current process and then start Script 3 again\n",
    "        self.stop_processing()\n",
    "        self.log(\"Restarting processing...\")\n",
    "        self.start_processing_3()\n",
    "\n",
    "    def start_processing(self):\n",
    "        # Flag to indicate that processing is active\n",
    "        self.processing_active = True\n",
    "\n",
    "        # Reset the stop event in case it was triggered during a previous run\n",
    "        self.stop_event.clear()\n",
    "\n",
    "        # Validate that all necessary folders (BF, PL, and Output) have been selected\n",
    "        if not self.input_folder or not self.output_folder:\n",
    "            self.log(\"Please select all folders before starting.\")\n",
    "            return\n",
    "\n",
    "        # Create the output directory if it doesn't already exist\n",
    "        os.makedirs(self.output_folder, exist_ok=True)\n",
    "\n",
    "        # Collect and sort all .tif files in both BF and PL folders\n",
    "        input_file = sorted([f for f in os.listdir(self.input_folder) if f.endswith('.png')])\n",
    "        #input_file = sorted([f for f in os.listdir(self.input_folder) if f.endswith('.jpeg')])\n",
    "\n",
    "        # List to keep track of output files generated during processing\n",
    "        all_output_files = []\n",
    "\n",
    "        # Batch process each image file\n",
    "        for file_name in input_file:\n",
    "            print(f\"Processing: {file_name}\")\n",
    "\n",
    "            # Allow user to stop processing midway\n",
    "            if self.stop_event.is_set():\n",
    "                self.log(\"Processing stopped.\")\n",
    "                return\n",
    "\n",
    "            self.log(f\"Processing {file_name}...\")\n",
    "\n",
    "            # Load image\n",
    "            input_image_path = os.path.join(self.input_folder, file_name)\n",
    "            imageA = cv2.imread(input_image_path)\n",
    "\n",
    "            # Convert BF image to grayscale\n",
    "            grayA = rgb2gray(imageA)\n",
    "\n",
    "            # Convert to uint8, range [0,255]\n",
    "            grayA = (grayA * 255).astype(np.uint8)\n",
    "\n",
    "            # Define Gabor orientations in radians (0°, 45°, 90°)\n",
    "            orientations = [0, np.pi/4, np.pi/2]##[0, np.pi/4, np.pi/2]\n",
    "            frequency = 0.15#0.2\n",
    "\n",
    "            # Apply Gabor filters and take maximum response\n",
    "            gabor_responses = []\n",
    "            for theta in orientations:\n",
    "                real, _ = gabor(grayA, frequency=frequency, theta=theta)\n",
    "                gabor_responses.append(real)\n",
    "\n",
    "            # Combine responses by taking the maximum pixel-wise value\n",
    "            gabor_combined = np.max(np.stack(gabor_responses, axis=0), axis=0)\n",
    "\n",
    "            # Normalize to 0-255\n",
    "            gabor_norm = exposure.rescale_intensity(gabor_combined, out_range=(0, 255)).astype(np.uint8)\n",
    "\n",
    "            # Threshold using Otsu\n",
    "            _, binary_A = cv2.threshold(gabor_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            binary_A = morphology.dilation(binary_A, morphology.disk(2))#add\n",
    "            binary_A = morphology.closing(binary_A, morphology.disk(2))#add\n",
    "            binary_A = morphology.erosion(binary_A, morphology.disk(2))#add\n",
    "            binary_A = (binary_A * 255).astype(np.uint8)\n",
    "\n",
    "            # Save results\n",
    "            cv2.imwrite(\"gabor_combined_response.png\", gabor_norm)\n",
    "            cv2.imwrite(\"gabor_segmented_mask.png\", binary_A)\n",
    "\n",
    "            # Show result\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(gabor_norm, cmap='gray')\n",
    "            plt.title(\"Gabor Combined Response\")\n",
    "            plt.axis('off')\n",
    "            plt.pause(0.001)\n",
    "            QApplication.processEvents()\n",
    "            plt.close()\n",
    "\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(binary_A)\n",
    "            plt.title(\"Segmented\")\n",
    "            plt.axis('off')\n",
    "            plt.pause(0.001)\n",
    "            QApplication.processEvents()\n",
    "            plt.close()\n",
    "    \n",
    "            # Label connected regions\n",
    "            region_labels_A = label(binary_A)\n",
    "            region_props_A = regionprops(region_labels_A)\n",
    "            \n",
    "            # Ensure binary mask matches grayscale shape\n",
    "            if binary_A.shape != grayA.shape:\n",
    "                binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "            # Annotate region labels on binary image\n",
    "            #overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "            #for region in regionprops(region_labels_A):\n",
    "            #    y, x = region.centroid\n",
    "            #    label_id = region.label\n",
    "            #    cv2.putText(overlay_image, str(region.label), (int(x), int(y)),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            #----------------new-----------------------------------------------------------------------------------------------------\n",
    "            # --- Color overlay for multi-component segmentation ---\n",
    "            overlay_colored = label2rgb(region_labels_A, image=imageA, bg_label=0)\n",
    "            overlay_colored_uint8 = (overlay_colored * 255).astype(np.uint8)\n",
    "\n",
    "            overlay_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_MultiComponent_Overlay.png\")\n",
    "            cv2.imwrite(overlay_path, overlay_colored_uint8)\n",
    "            print(f\"Saved multi-color segmentation overlay to {overlay_path}\")\n",
    "            all_output_files.append(overlay_path)\n",
    "\n",
    "            # Optional: annotate regions with labels on overlay\n",
    "            overlay_image = overlay_colored_uint8.copy()\n",
    "            for region in region_props_A:\n",
    "                y, x = region.centroid\n",
    "                cv2.putText(overlay_image, str(region.label), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            #--------------------------------------------------------------------------------------------------------------------\n",
    "            # Save annotated segmentation image\n",
    "            annotated_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_Segmented_Annotated.png\")\n",
    "            cv2.imwrite(annotated_path, overlay_image)\n",
    "            print(f\"Saved annotated image with labels to {annotated_path}\")\n",
    "            all_output_files.append(annotated_path)\n",
    "\n",
    "            # Create binary mask with only valid detected regions\n",
    "            filtered_binary_A = np.zeros_like(binary_A)\n",
    "            for prop in region_props_A:\n",
    "                if prop.area > 0:\n",
    "                    min_row, min_col, max_row, max_col = prop.bbox\n",
    "                    filtered_binary_A[min_row:max_row, min_col:max_col] = (\n",
    "                        region_labels_A[min_row:max_row, min_col:max_col] == prop.label\n",
    "                    )\n",
    "            filtered_binary_A = (filtered_binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "            # --- Save region statistics to Excel ---\n",
    "            region_area_df = pd.DataFrame({\n",
    "                \"Region_Label\": [region.label for region in region_props_A],\n",
    "                \"Region_Area (pixels)\": [region.area for region in region_props_A],\n",
    "            })\n",
    "\n",
    "            total_area = region_area_df[\"Region_Area (pixels)\"].sum()\n",
    "            total_detect = region_area_df[\"Region_Label\"].count()\n",
    "\n",
    "            # Append summary rows\n",
    "            region_area_df.loc[\"Total Area\"] = [\"Total Area\", total_area]\n",
    "            region_area_df.loc[\"Total\"] = [\"Total\", total_detect]\n",
    "\n",
    "            # Save region stats to Excel\n",
    "            region_area_excel_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_Region_Area.xlsx\")\n",
    "            region_area_df.to_excel(region_area_excel_path, index=False)\n",
    "            print(f\"Saved region areas for {file_name} to {region_area_excel_path}\")\n",
    "        \n",
    "            del grayA, binary_A, region_labels_A, region_props_A, overlay_image, filtered_binary_A\n",
    "            gc.collect()\n",
    "\n",
    "        self.log(\"Processing complete!\")\n",
    "        \n",
    "        # -----------------------------------------------------\n",
    "        # Create a ZIP archive with all output histogram and annotated image files\n",
    "        zip_path = os.path.join(self.output_folder, \"All_Images_histograms.zip\")\n",
    "        with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "            for file_path in all_output_files:\n",
    "                zipf.write(file_path, arcname=os.path.basename(file_path))\n",
    "                \n",
    "        # Remove the original files after archiving\n",
    "        for file_path in all_output_files:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "    def start_processing_2(self):\n",
    "        # Flag to indicate that processing is active\n",
    "        self.processing_active = True\n",
    "\n",
    "        # Reset the stop event in case it was triggered during a previous run\n",
    "        self.stop_event.clear()\n",
    "\n",
    "        # Validate that all necessary folders (BF, PL, and Output) have been selected\n",
    "        if not self.input_folder or not self.output_folder:\n",
    "            self.log(\"Please select all folders before starting.\")\n",
    "            return\n",
    "\n",
    "        # Create the output directory if it doesn't already exist\n",
    "        os.makedirs(self.output_folder, exist_ok=True)\n",
    "\n",
    "        # Collect and sort all .tif files in both BF and PL folders\n",
    "        input_file = sorted([f for f in os.listdir(self.input_folder) if f.endswith('.png')])\n",
    "        #input_file = sorted([f for f in os.listdir(self.input_folder) if f.endswith('.jpeg')])\n",
    "\n",
    "        # List to keep track of output files generated during processing\n",
    "        all_output_files = []\n",
    "\n",
    "        # Batch process each image file\n",
    "        for file_name in input_file:\n",
    "            print(f\"Processing: {file_name}\")\n",
    "\n",
    "            # Allow user to stop processing midway\n",
    "            if self.stop_event.is_set():\n",
    "                self.log(\"Processing stopped.\")\n",
    "                return\n",
    "\n",
    "            self.log(f\"Processing {file_name}...\")\n",
    "\n",
    "            # Load image\n",
    "            input_image_path = os.path.join(self.input_folder, file_name)\n",
    "            imageA = cv2.imread(input_image_path)\n",
    "\n",
    "            # === Parameters ===\n",
    "            output_binary_path = \"binary_mask_gabor_otsu.png\"\n",
    "\n",
    "            # === Extract Magenta Channel ===\n",
    "            magenta = imageA[..., 0] + imageA[..., 2]  # R + B\n",
    "            magenta = np.clip(magenta, 0, 255).astype(np.uint8)\n",
    "\n",
    "            # Define Gabor orientations in radians (0°, 45°, 90°)\n",
    "            orientations = [0, np.pi/4, np.pi/2]##[0, np.pi/4, np.pi/2]\n",
    "            frequency = 0.15#0.2\n",
    "\n",
    "            # Apply Gabor filters and take maximum response\n",
    "            gabor_responses = []\n",
    "            for theta in orientations:\n",
    "                real, _ = gabor(magenta, frequency=frequency, theta=theta)\n",
    "                gabor_responses.append(real)\n",
    "\n",
    "            # Combine responses by taking the maximum pixel-wise value\n",
    "            gabor_combined = np.max(np.stack(gabor_responses, axis=0), axis=0)\n",
    "\n",
    "            # Normalize to 0-255\n",
    "            gabor_norm = exposure.rescale_intensity(gabor_combined, out_range=(0, 255)).astype(np.uint8)\n",
    "\n",
    "            # Threshold using Otsu\n",
    "            _, binary_A = cv2.threshold(gabor_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            binary_A = morphology.dilation(binary_A, morphology.disk(1))#add#2.5 funciona\n",
    "            binary_A = morphology.closing(binary_A, morphology.disk(1))#add#2.5 funciona\n",
    "            binary_A = morphology.erosion(binary_A, morphology.disk(1))#add\n",
    "            binary_A = (binary_A * 255).astype(np.uint8)\n",
    "\n",
    "            # Save results\n",
    "            cv2.imwrite(\"gabor_combined_response.png\", gabor_norm)\n",
    "            cv2.imwrite(\"gabor_segmented_mask.png\", binary_A)\n",
    "\n",
    "            # Show result\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(gabor_norm, cmap='gray')\n",
    "            plt.title(\"Gabor Combined Response\")\n",
    "            plt.axis('off')\n",
    "            plt.pause(0.001)\n",
    "            QApplication.processEvents()\n",
    "            plt.close()\n",
    "\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(binary_A)\n",
    "            plt.title(\"Segmented\")\n",
    "            plt.axis('off')\n",
    "            plt.pause(0.001)\n",
    "            QApplication.processEvents()\n",
    "            plt.close()\n",
    "\n",
    "            # Label connected regions\n",
    "            region_labels_A = label(binary_A)\n",
    "            region_props_A = regionprops(region_labels_A)\n",
    "            \n",
    "            # Ensure binary mask matches grayscale shape\n",
    "            if binary_A.shape != magenta.shape:\n",
    "                binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "            # Annotate region labels on binary image\n",
    "            #overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "            #for region in regionprops(region_labels_A):\n",
    "            #    y, x = region.centroid\n",
    "            #    label_id = region.label\n",
    "            #    cv2.putText(overlay_image, str(region.label), (int(x), int(y)),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            #----------------new-----------------------------------------------------------------------------------------------------\n",
    "            # --- Color overlay for multi-component segmentation ---\n",
    "            overlay_colored = label2rgb(region_labels_A, image=imageA, bg_label=0)\n",
    "            overlay_colored_uint8 = (overlay_colored * 255).astype(np.uint8)\n",
    "\n",
    "            overlay_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_MultiComponent_Overlay.png\")\n",
    "            cv2.imwrite(overlay_path, overlay_colored_uint8)\n",
    "            print(f\"Saved multi-color segmentation overlay to {overlay_path}\")\n",
    "            all_output_files.append(overlay_path)\n",
    "\n",
    "            # Optional: annotate regions with labels on overlay\n",
    "            overlay_image = overlay_colored_uint8.copy()\n",
    "            for region in region_props_A:\n",
    "                y, x = region.centroid\n",
    "                cv2.putText(overlay_image, str(region.label), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            #--------------------------------------------------------------------------------------------------------------------\n",
    "            # Save annotated segmentation image\n",
    "            annotated_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_Segmented_Annotated.png\")\n",
    "            cv2.imwrite(annotated_path, overlay_image)\n",
    "            print(f\"Saved annotated image with labels to {annotated_path}\")\n",
    "            all_output_files.append(annotated_path)\n",
    "\n",
    "            # Create binary mask with only valid detected regions\n",
    "            filtered_binary_A = np.zeros_like(binary_A)\n",
    "            for prop in region_props_A:\n",
    "                if prop.area > 0:\n",
    "                    min_row, min_col, max_row, max_col = prop.bbox\n",
    "                    filtered_binary_A[min_row:max_row, min_col:max_col] = (\n",
    "                        region_labels_A[min_row:max_row, min_col:max_col] == prop.label\n",
    "                    )\n",
    "            filtered_binary_A = (filtered_binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "            # --- Save region statistics to Excel ---\n",
    "            region_area_df = pd.DataFrame({\n",
    "                \"Region_Label\": [region.label for region in region_props_A],\n",
    "                \"Region_Area (pixels)\": [region.area for region in region_props_A],\n",
    "            })\n",
    "\n",
    "            total_area = region_area_df[\"Region_Area (pixels)\"].sum()\n",
    "            total_detect = region_area_df[\"Region_Label\"].count()\n",
    "\n",
    "            # Append summary rows\n",
    "            region_area_df.loc[\"Total Area\"] = [\"Total Area\", total_area]\n",
    "            region_area_df.loc[\"Total\"] = [\"Total\", total_detect]\n",
    "\n",
    "            # Save region stats to Excel\n",
    "            region_area_excel_path = os.path.join(self.output_folder, f\"{os.path.splitext(file_name)[0]}_Region_Area.xlsx\")\n",
    "            region_area_df.to_excel(region_area_excel_path, index=False)\n",
    "            print(f\"Saved region areas for {file_name} to {region_area_excel_path}\")\n",
    "            \n",
    "            del magenta, binary_A, region_labels_A, region_props_A, overlay_image, filtered_binary_A\n",
    "            gc.collect()\n",
    "\n",
    "        self.log(\"Processing complete!\")\n",
    "        \n",
    "        # -----------------------------------------------------\n",
    "        # Create a ZIP archive with all output histogram and annotated image files\n",
    "        zip_path = os.path.join(self.output_folder, \"All_Images_histograms.zip\")\n",
    "        with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "            for file_path in all_output_files:\n",
    "                zipf.write(file_path, arcname=os.path.basename(file_path))\n",
    "                \n",
    "        # Remove the original files after archiving\n",
    "        for file_path in all_output_files:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "\n",
    "# Entry point of the application\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a Qt application instance\n",
    "    app = QApplication(sys.argv)\n",
    "\n",
    "    # Instantiate the main window (custom image processing GUI)\n",
    "    window = ImageProcessingApp()\n",
    "\n",
    "    # Show the main window\n",
    "    window.show()\n",
    "\n",
    "    # Execute the Qt event loop and exit the application when it's closed\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5de1b3-d72f-405b-a040-096e94345234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .czi file\n",
    "img = \"C://Users//nahue//Downloads//Airy scan_40A_UAS-TMEM-HA_CB_4h_1_051222.tif\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "# ==== Load 3D Volume ====\n",
    "# --- Option A: TIFF stack ---\n",
    "from tifffile import imread\n",
    "\n",
    "volume_raw = imread(img)  # shape: (Z, C, Y, X)\n",
    "print(\"Raw shape:\", volume_raw.shape)\n",
    "\n",
    "# Select first channel (C=0)\n",
    "volume = volume_raw[:, 0, :, :]  # shape: (Z, Y, X)\n",
    "print(\"Fixed shape:\", volume.shape)\n",
    "\n",
    "# # --- Option B: NIfTI file ---\n",
    "# import nibabel as nib\n",
    "# nii = nib.load(\"your_image.nii\")\n",
    "# volume = nii.get_fdata()\n",
    "\n",
    "print(\"Loaded volume shape:\", volume.shape)  # Should be (Z, Y, X)\n",
    "\n",
    "# ==== Preprocess ====\n",
    "# Normalize intensity\n",
    "volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
    "\n",
    "# Otsu threshold\n",
    "thresh = threshold_otsu(volume)\n",
    "binary = volume > thresh\n",
    "\n",
    "# Optional: Remove small noise\n",
    "binary = remove_small_objects(binary, min_size=200)\n",
    "\n",
    "# ==== Watershed Segmentation ====\n",
    "# Compute distance map\n",
    "distance = distance_transform_edt(binary)\n",
    "\n",
    "# Detect local maxima\n",
    "coords = peak_local_max(distance, labels=binary, footprint=np.ones((3, 3, 3)), exclude_border=False)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = label(mask)\n",
    "\n",
    "# Apply 3D watershed\n",
    "labels_ws = watershed(-distance, markers, mask=binary)\n",
    "\n",
    "# ==== Visualize One Slice ====\n",
    "z = volume.shape[0] // 2\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(volume[z], cmap='gray')\n",
    "plt.title('Original (Z slice)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(labels_ws[z], cmap='nipy_spectral')\n",
    "plt.title('Watershed segmentation')\n",
    "plt.show()\n",
    "\n",
    "#import imageio\n",
    "\n",
    "#frames = [(labels_ws[z] * 10).astype(np.uint8) for z in range(volume.shape[0])]\n",
    "#imageio.mimsave(\"segmentation_z_stack.gif\", frames, duration=0.1)\n",
    "\n",
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(volume, name='Image')         # 3D grayscale\n",
    "viewer.add_labels(labels_ws, name='Labels')    # 3D segmentation labels\n",
    "napari.run()\n",
    "\n",
    "from skimage.measure import regionprops_table\n",
    "import pandas as pd\n",
    "\n",
    "props = regionprops_table(labels_ws, properties=['label', 'area', 'centroid'])\n",
    "df = pd.DataFrame(props)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b0187-5133-4aa6-9553-2f182e654350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probar\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage import exposure\n",
    "\n",
    "# --- Load 3D Volume from TIFF ---\n",
    "path = \"your_image_stack.tif\"  # Replace with your converted 3D TIFF file\n",
    "volume = imread(path)  # shape: (Z, Y, X)\n",
    "print(f\"Loaded volume with shape: {volume.shape}\")\n",
    "\n",
    "# --- Normalize volume ---\n",
    "volume = exposure.rescale_intensity(volume.astype(np.float32))\n",
    "\n",
    "# --- Threshold using Otsu ---\n",
    "thresh = threshold_otsu(volume)\n",
    "binary = volume > thresh\n",
    "print(f\"Applied Otsu threshold: {thresh:.4f}\")\n",
    "\n",
    "# --- Distance transform ---\n",
    "distance = distance_transform_edt(binary)\n",
    "\n",
    "# --- Marker detection ---\n",
    "coords = peak_local_max(distance, labels=binary, footprint=np.ones((3, 3, 3)), exclude_border=False)\n",
    "marker_mask = np.zeros_like(distance, dtype=bool)\n",
    "marker_mask[tuple(coords.T)] = True\n",
    "markers, _ = label(marker_mask)\n",
    "\n",
    "# --- Watershed segmentation ---\n",
    "labels = watershed(-distance, markers, mask=binary)\n",
    "print(f\"Segmented {labels.max()} regions\")\n",
    "\n",
    "# --- Visualize central Z-slice ---\n",
    "zmid = volume.shape[0] // 2\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(volume[zmid], cmap='gray')\n",
    "plt.title(\"Original Z-slice\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(labels[zmid], cmap='nipy_spectral')\n",
    "plt.title(\"Labeled Z-slice\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- View interactively in napari (optional) ---\n",
    "try:\n",
    "    import napari\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(volume, name=\"Original\")\n",
    "    viewer.add_labels(labels, name=\"3D Segmentation\")\n",
    "    napari.run()\n",
    "except ImportError:\n",
    "    print(\"Install napari with `pip install napari[all]` for 3D interactive view.\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "OPTIONAL\n",
    "import nibabel as nib\n",
    "nii = nib.load(\"your_stack.nii.gz\")\n",
    "volume = nii.get_fdata()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae88b83-3983-4984-b386-6ffd74e17cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import remove_small_objects\n",
    "from tifffile import imread, imwrite\n",
    "from skimage.measure import regionprops_table\n",
    "import pandas as pd\n",
    "import imageio\n",
    "\n",
    "# ==== Load Image ====\n",
    "img = \"C://Users//nahue//Downloads//Airy scan_40A_UAS-TMEM-HA_CB_4h_1_051222.tif\"\n",
    "volume_raw = imread(img)\n",
    "print(\"Raw shape:\", volume_raw.shape)\n",
    "\n",
    "# Select first channel\n",
    "volume = volume_raw[:, 0, :, :]\n",
    "print(\"Volume shape:\", volume.shape)\n",
    "\n",
    "# ==== Preprocess ====\n",
    "volume = (volume - volume.min()) / (volume.max() - volume.min())\n",
    "thresh = threshold_otsu(volume)\n",
    "binary = volume > thresh\n",
    "binary = remove_small_objects(binary, min_size=200)\n",
    "\n",
    "# ==== Segmentation ====\n",
    "distance = distance_transform_edt(binary)\n",
    "coords = peak_local_max(distance, labels=binary, footprint=np.ones((3, 3, 3)), exclude_border=False)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = label(mask)\n",
    "labels_ws = watershed(-distance, markers, mask=binary)\n",
    "\n",
    "# ==== Visualize 6 Slices ====\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20,12))#2,3\n",
    "step = max(1, volume.shape[0] // 12)#6\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    z = i * step\n",
    "    ax.imshow(labels_ws[z], cmap=\"nipy_spectral\")\n",
    "    ax.set_title(f\"Z = {z}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==== Export segmentation as TIF ====\n",
    "imwrite(\"segmentation_labels.tif\", labels_ws.astype(np.uint16))\n",
    "imwrite(\"intensity_volume.tif\", (volume * 255).astype(np.uint8))\n",
    "\n",
    "# ==== Export animated GIF ====\n",
    "frames = [(labels_ws[z] * 10).astype(np.uint8) for z in range(volume.shape[0])]\n",
    "imageio.mimsave(\"segmentation_stack.gif\", frames, duration=0.1)\n",
    "\n",
    "# ==== Export measurements ====\n",
    "props = regionprops_table(labels_ws, properties=['label', 'area', 'centroid'])\n",
    "df = pd.DataFrame(props)\n",
    "df.to_csv(\"segmentation_measurements.csv\", index=False)\n",
    "#print(\"Exported segmentation and region data.\")\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80900704-fe4f-4aad-a2fc-523cdd18f9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
